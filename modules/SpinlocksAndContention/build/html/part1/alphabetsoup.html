<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>MIMD, TTAS, and Other Alphabet Soup &mdash; Spinlocks and Contention</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Spinlocks and Contention" href="../index.html" />
    <link rel="next" title="Solving the Mystery and Using Our Findings" href="../part2/backoffandqueue.html" />
    <link rel="prev" title="Spinlocks and Contention" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../part2/backoffandqueue.html" title="Solving the Mystery and Using Our Findings"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="Spinlocks and Contention"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Spinlocks and Contention</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="mimd-ttas-and-other-alphabet-soup">
<h1>MIMD, TTAS, and Other Alphabet Soup<a class="headerlink" href="#mimd-ttas-and-other-alphabet-soup" title="Permalink to this headline">¶</a></h1>
<p>In this module, we&#8217;re going to dig into exactly which aspects of reality matter in multithread protocols and which do not. If you&#8217;ve done any study of concurrency or locks, you&#8217;ve probably been looking at simpler models that were <em>accurate</em> (none of it was untrue) but <em>idealized</em> (some things were left out). In this module we transition to the &#8220;real&#8221; world and look at the kinds of protocols you might actually use. These models are necessarily more <em>complicated</em>, in the sense of having more details and exceptions and things to remember, but not necessarily more <em>complex</em>, in the sense of encompassing deeper ideas. We are still going to focus on issues that are important - that is, things that matter for all kinds of platforms and applications and thereby become obsolete less quickly than highly specialized material.</p>
<div class="section" id="background-types-of-architectures">
<h2>Background: Types of Architectures<a class="headerlink" href="#background-types-of-architectures" title="Permalink to this headline">¶</a></h2>
<p>We can classify processors by how they manage data and instruction streams. A single-instruction, single-data stream (SISD) architecture is just a uniprocessor. A few years ago, single-instruction multiple-data stream (SIMD) architectures were popular - for example, the Connection Machine CM2. These vector processors have fallen out of favor with desktop machines, at least for the time being, although they are still used for multimedia applications. Instead, most modern multiprocessors provide <em>multiple instruction streams</em>, meaning that processors execute independent sequences of instructions, and <em>multiple data streams</em>, meaning that processors issue independent sequences of memory reads and writes. Such architectures are usually called MIMD (for, as you&#8217;ve probably guessed, multi-instruction, multiple-data stream).</p>
<p>When programming uniprocessors, one can generally ignore the exact structure and properties of the underlying system. Unfortunately, multiprocessor programming has yet to reach that state, and at present it is crucial that the programmer understand the properties and limitations of the underlying machine architecture. This will be our goal in this module. We revisit the familiar mutual exclusion problem, this time with the aim of devising mutual exclusion protocols that work well on today’s multiprocessors. Our goals are as follows:</p>
<blockquote>
<div><ul class="simple">
<li>Think of performance, not just correctness and progress</li>
<li>Begin to understand how performance depends on our software properly utilizing the multiprocessor machine’s hardware</li>
<li>Get to know a collection of locking algorithms</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="multiprocessor-architecture">
<h2>Multiprocessor Architecture<a class="headerlink" href="#multiprocessor-architecture" title="Permalink to this headline">¶</a></h2>
<p>There are two basic kinds of MIMD architectures. In a <em>shared bus</em> architecture, processors and memory are connected by a shared broadcast medium called a bus (like a tiny Ethernet). Both the processors and the memory controller can broadcast on the bus. Only one processor (or memory) can broadcast on the bus at a time, but all processors (and memory) can listen - we call this snooping, but it&#8217;s an expected part of the architecture and not something unethical). Bus-based architectures are the most common today because they are easy to build.</p>
<p>In the other type of MIMD architecture shown below, a <em>distributed system</em>, each processor has its own memory and can perform local computations on it. Information that needs to be shared has to be communicated via message passing.</p>
<a class="reference internal image-reference" href="../_images/mimdarchs.png"><img alt="Diagram showing memory in shared-bus and distributed architectures." class="align-center" src="../_images/mimdarchs.png" style="width: 368.4px; height: 162.0px;" /></a>
<p>The principal things that affect performance of MIMD systems are a growing <em>communication latency</em> - the the time it takes for a processor to communicate with memory or with another processor - and two types of <em>contention</em>. Contention occurs when multiple threads try to acquire a shared resource at the same time; they are stopped from doing this by a <em>mutual exclusion protocol</em>. <em>Contention for the memory</em> occurs when processors try to get at the same memory location at the same time; usually they can&#8217;t, and if they try, they have to queue up. <em>Contention for the communication medium</em> occurs when processors try to communicate at the same time or to the same processor, forcing them to wait for one another.</p>
</div>
<div class="section" id="when-you-can-t-get-a-lock">
<h2>When You Can&#8217;t Get a Lock<a class="headerlink" href="#when-you-can-t-get-a-lock" title="Permalink to this headline">¶</a></h2>
<p>Any mutual exclusion protocol poses the question: what do you do when you cannot acquire the lock? There are two alternatives. If you keep trying, the lock is called a <em>spin lock</em>, and repeatedly testing the lock is called <em>spinning</em> or <em>busy-waiting</em>(we will use these terms interchangeably). The <a class="reference external" href="http://en.wikipedia.org/wiki/Peterson's_algorithm#Filter_algorithm:_Peterson.27s_algorithm_for_N_processes">filter</a> and <a class="reference external" href="http://en.wikipedia.org/wiki/Lamport's_bakery_algorithm#Algorithm">bakery</a> algorithms are spin-locks. Spinning is sensible when you expect the lock delay to be short. For obvious reasons, spinning makes sense only on multiprocessors.</p>
<p>The alternative to spinning or busy-waiting is to suspend yourself and ask the operating system&#8217;s scheduler to schedule another thread on your processor, which is sometimes called <em>blocking</em>. Java’s built-in synchronization is blocking. Because switching from one thread to another is expensive, blocking makes sense only if you expect the lock delay to be long. Many operating systems mix both strategies, spinning for a short time and then blocking.</p>
<div class="section" id="spinlocks">
<h3>Spinlocks<a class="headerlink" href="#spinlocks" title="Permalink to this headline">¶</a></h3>
<p>With spin locks, synchronization usually looks like this: some set of threads <em>contend</em> for the lock. One of them (the blue processor, in this image) <em>acquires</em> it, and the others spin. The winner enters the critical section, does its job, and <em>releases</em> the lock on exit.</p>
<a class="reference internal image-reference" href="../_images/spinlocks1.png"><img alt="Basic spin lock, part 1." class="align-center" src="../_images/spinlocks1.png" style="width: 330.55px; height: 191.95px;" /></a>
<p>There is extra delay just to get through the lock itself: the lock introduces sequential bottleneck, effectively negating the parallelism.</p>
<a class="reference internal image-reference" href="../_images/spinlocks2.png"><img alt="Basic spin lock, part 2." class="align-center" src="../_images/spinlocks2.png" style="width: 364.2px; height: 189.6px;" /></a>
<p>The lock suffers from <em>contention</em>. Again, contention occurs when multiple threads try to acquire a lock at the same time (<em>high contention</em>, many such threads; <em>low contention</em>, the opposite).</p>
<a class="reference internal image-reference" href="../_images/spinlocks3.png"><img alt="Basic spin lock, part 3." class="align-center" src="../_images/spinlocks3.png" style="width: 302.5px; height: 185.9px;" /></a>
<p>Note that sequential bottleneck and contention are <strong>distinct phenomena</strong>. Our goal is to understand how contention works, and to develop a set of techniques that can avoid or alleviate it. These techniques provide a useful toolkit for all kinds of synchronization problems. We are not trying to resolve the sequential bottleneck in this module; we are only looking at ways to manage contention and busy-wait more efficiently.</p>
</div>
<div class="section" id="two-ways-to-build-spinlocks">
<h3>Two Ways to Build Spinlocks<a class="headerlink" href="#two-ways-to-build-spinlocks" title="Permalink to this headline">¶</a></h3>
<div class="section" id="test-and-set">
<h4>Test-and-Set<a class="headerlink" href="#test-and-set" title="Permalink to this headline">¶</a></h4>
<p>The test-and-set machine instruction operates on a single memory word which holds a binary value (either true or false). <tt class="docutils literal"><span class="pre">testAndSet()</span></tt> atomically stores <em>true</em> in that word and returns the word&#8217;s previous value, <em>swapping</em> the value <em>true</em> for the word&#8217;s current value.  <tt class="docutils literal"><span class="pre">lock()</span></tt> calls <tt class="docutils literal"><span class="pre">testAndSet()</span></tt> until it returns false (thereby indicating that the lock was free); you can reset the word just by writing false to it. Note that in Java TAS is called <tt class="docutils literal"><span class="pre">getAndSet()</span></tt>, and we will use the terms interchangeably.</p>
<p>Here, we implement <tt class="docutils literal"><span class="pre">getAndSet()</span></tt> using Java&#8217;s AtomicBoolean class, which is provided as part of Java’s standard library of atomic primitives and can be thought of as a box holding a Boolean value. <tt class="docutils literal"><span class="pre">getAndSet()</span></tt> swaps a Boolean value with the current contents of the box.</p>
<div class="highlight-java"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AtomicBoolean</span> <span class="o">{</span>
        <span class="kt">boolean</span> <span class="n">value</span><span class="o">;</span>

        <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">getAndSet</span><span class="o">(</span><span class="kt">boolean</span> <span class="n">newValue</span><span class="o">)</span> <span class="o">{</span>
                <span class="kt">boolean</span> <span class="n">prior</span> <span class="o">=</span> <span class="n">value</span><span class="o">;</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">newValue</span><span class="o">;</span>
                <span class="k">return</span> <span class="n">prior</span><span class="o">;</span>
        <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</td></tr></table></div>
<p>At first, this seems ideal for implementing a spin lock. The lock is free when the word&#8217;s value is false, and busy when it is true. If we call <tt class="docutils literal"><span class="pre">getAndSet(true)</span></tt>, then we have a test-and-set.</p>
<p>Below is the full code for a TASlock. The lock is just an <tt class="docutils literal"><span class="pre">AtomicBoolean</span></tt> initialized to false. The <tt class="docutils literal"><span class="pre">lock()</span></tt> method repeatedly applies <tt class="docutils literal"><span class="pre">getAndSet()</span></tt> to the location until that instruction returns false (that is, until the lock is free). The <tt class="docutils literal"><span class="pre">unlock()</span></tt> method simply writes the value false to that word.</p>
<div class="highlight-java"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">TASlock</span> <span class="o">{</span>
        <span class="n">AtomicBoolean</span> <span class="n">state</span> <span class="o">=</span> <span class="k">new</span> <span class="n">AtomicBoolean</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

        <span class="kt">void</span> <span class="nf">lock</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">state</span><span class="o">.</span><span class="na">getAndSet</span><span class="o">(</span><span class="kc">true</span><span class="o">))</span> <span class="o">{}</span>
        <span class="o">}</span>

        <span class="kt">void</span> <span class="nf">unlock</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">state</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
        <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</td></tr></table></div>
<p>We call real-world space complexity the “footprint”, and by using <tt class="docutils literal"><span class="pre">testAndSet()</span></tt> we are able to reduce the footprint from linear (as in the filter and bakery locks) to constant. Because it uses an atomic <a class="reference external" href="http://en.wikipedia.org/wiki/Read%E2%80%93modify%E2%80%93write">RMW</a> operation, an <em>n</em>-thread spinlock uses O(1) space.</p>
<p>Let’s do an experiment on a real machine. Take <em>n</em> threads and have them collectively acquire a lock, increment a counter, and release the lock. Have them do it collectively, say, one million times. Before we look at any curves, let’s try to reason about how long it <em>should</em> take them.</p>
<p>Ideally the curve should stay flat, like the graph below. Why? Because we have a sequential bottleneck, so no matter how many threads we add running in parallel, we will not get any speedup (remember <a class="reference external" href="http://en.wikipedia.org/wiki/Amdahl's_law">Amdahl</a>’s law).</p>
<div class="align-center figure">
<a class="reference internal image-reference" href="../_images/idealgraph.png"><img alt="Graph showing how long TAS should take, in theory." src="../_images/idealgraph.png" style="width: 192.0px; height: 134.4px;" /></a>
</div>
<p>However, the curve for the TAS lock looks like this. In fact, if you do the experiment you have to give up because it takes so long beyond a certain number of processors. What is happening?</p>
<div class="align-center figure">
<a class="reference internal image-reference" href="../_images/actualgraph.png"><img alt="Graph showing how long TAS actually takes." src="../_images/actualgraph.png" style="width: 234.0px; height: 149.25px;" /></a>
</div>
</div>
<div class="section" id="test-and-test-and-set">
<h4>Test-and-test-and-set<a class="headerlink" href="#test-and-test-and-set" title="Permalink to this headline">¶</a></h4>
<p>Let’s try a slightly different approach. Instead of repeatedly trying to test-and-set the lock, let’s split the locking method into two phases. In the <em>lurking</em> phase, we wait until the lock looks like it’s free, spinning while read returns true. When it’s free, we <em>pounce</em>, attempting to acquire the lock by a call to test-and-set. If we win, we’re in, and if we lose, we go back to lurking. It looks like this:</p>
<div class="highlight-java"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">TTASlock</span> <span class="o">{</span>
        <span class="n">AtomicBoolean</span> <span class="n">state</span> <span class="o">=</span> <span class="k">new</span> <span class="n">AtomicBoolean</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

        <span class="kt">void</span> <span class="nf">lock</span><span class="o">()</span> <span class="o">{</span>
                <span class="k">while</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>
                        <span class="k">while</span> <span class="o">(</span><span class="n">state</span><span class="o">.</span><span class="na">get</span><span class="o">())</span> <span class="o">{}</span>
<span class="hll">                        <span class="k">if</span> <span class="o">(!</span><span class="n">state</span><span class="o">.</span><span class="na">getAndSet</span><span class="o">(</span><span class="kc">true</span><span class="o">))</span>
</span><span class="hll">                <span class="k">return</span><span class="o">;</span>
</span>                <span class="o">}</span>
        <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</td></tr></table></div>
<p>The highlighted lines are key steps: first we spin on the value, repeatedly reading it until it looks like the lock is free. We don’t try to modify it, we just read it. As soon as it looks like the lock is free, <em>then</em> we call <tt class="docutils literal"><span class="pre">getAndSet(true)</span></tt> to try to acquire it. If we are first and we succeed, the <tt class="docutils literal"><span class="pre">lock()</span></tt> method returns, and otherwise, if someone else got there before us, we go back to lurking (repeatedly rereading the variable).</p>
<a class="reference internal image-reference" href="../_images/ttasgraph.png"><img alt="Timing of TAS vs TTAS vs ideal." class="align-center" src="../_images/ttasgraph.png" style="width: 281.0px; height: 174.0px;" /></a>
<p>The difference is dramatic. The TTAS lock performs much better than the TAS lock, but still much worse than we expected from an ideal lock.</p>
<p>There are two mysteries here: why is the TTAS lock so good (that is, so much better than TAS), and why is it so bad (so much worse than ideal)?</p>
<p>We would expect the TAS and TTAS locks to be the same - after all, they are <em>logically</em> equivalent programs. In fact, they are equivalent with respect to <em>correctness</em> (they both work), but very different with respect to performance. The problem here is that the shared memory abstraction is broken with respect to <em>performance</em> - we need a more detailed model. If you don’t understand the underlying architecture, you will never understand why your reasonable-looking programs are so slow.</p>
</div>
</div>
</div>
<div class="section" id="multiprocessor-architecture-part-2">
<h2>Multiprocessor Architecture, part 2<a class="headerlink" href="#multiprocessor-architecture-part-2" title="Permalink to this headline">¶</a></h2>
<p>To solve the mysteries, we&#8217;ll do a more thorough review. Here is an example bus-based multiprocessor architecture. The processors share a memory that has a high latency (say, 50 to 100 cycles) to read or write a value. This means that while you are waiting for the memory to respond, that many instructions can be executed.</p>
<a class="reference internal image-reference" href="../_images/busbasedarch1.png"><img alt="Bus-based architectures." class="align-center" src="../_images/busbasedarch1.png" style="width: 247.6px; height: 150.0px;" /></a>
<p>Processors communicate with the memory and with one another over a shared bus. The bus is a broadcast medium, meaning that only one processor at a time can send a message, although everyone can (and does!) passively listen.</p>
<a class="reference internal image-reference" href="../_images/busbasedarch2.png"><img alt="Bus-based architectures." class="align-center" src="../_images/busbasedarch2.png" style="width: 251.6px; height: 169.2px;" /></a>
<p>Each processor has a <em>cache</em>, a small high-speed memory where the processor keeps data likely to be of interest. A cache access typically requires one or two machine cycles, while a memory access typically requires many machine cycles. Technology trends are making this contrast more extreme: although both processor cycle times and memory access times are becoming faster, the cycle times are improving faster than the memory access times, so cache performance is critical to the overall performance of a multiprocessor architecture.</p>
<a class="reference internal image-reference" href="../_images/busbasedarch3.png"><img alt="Bus-based architectures." class="align-center" src="../_images/busbasedarch3.png" style="width: 253.6px; height: 180.8px;" /></a>
<p>If a processor finds data in its cache, then it doesn’t have to go all the way to memory. This is a very good thing, which we call a <em>cache hit</em>. If the processor doesn’t find what it wants in its cache, then we have a <em>cache miss</em>, which is very time-consuming. How well a synchronization protocol or concurrent algorithm performs is largely determined by its cache behavior: how many hits and misses.</p>
<a class="reference internal image-reference" href="../_images/busbasedarch4.png"><img alt="Bus-based architectures." class="align-center" src="../_images/busbasedarch4.png" style="width: 285.2px; height: 215.6px;" /></a>
<p>The animation below shows cache behavior in action. The purple processor on the left issues a load request. It broadcasts a message asking for the data it needs. Notice that while it is broadcasting, no one else can use the bus. In this case, the memory responds to the request, also over the bus.</p>
<p>Then another processor (red, center) issues a load request for the same data. It broadcasts its request over the bus. This time, however, the request is picked up by the first processor, which has the data in its cache. Usually, when a processor has the data cached, it, rather than the memory, will respond to load requests. The first processor puts the data on the bus, and now both processors have the same data cached. Now what happens if the red processor decides to modify the cached data? It changes the copy in its cache (from blue to white). And now we have a problem: the data cached at the red processor disagrees with the same copy of that memory location stored both at the other processors and in the memory itself.</p>
<a class="reference internal image-reference" href="../_images/cachehit.gif"><img alt="Caching" class="align-center" src="../_images/cachehit.gif" style="width: 296.8px; height: 198.4px;" /></a>
<p>So now we have lots of copies of data: an original copy in memory and cached copies at processors. When one processor modifies its own copy, what do we do with the others? How do we avoid confusion? The problem of keeping track of multiple copies of the same data is called the <em>cache coherence problem</em>, and ways to accomplish it are called <em>cache coherence protocols</em>.</p>
<p>Warning: This is <em>still</em> a simplification; real cache coherence protocols can be very complex. For example, modern multiprocessors have multi-level caches, where each processor has an on-chip level-one (L1) cache, and clusters of processors share a level-two (L2) cache. The L2 cache is on chip in some modern architectures, and off chip in others - a detail that greatly changes the observed performance. We are going to avoid going into too much detail here, though, because the basic principles don&#8217;t depend on that level of detail.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">MIMD, TTAS, and Other Alphabet Soup</a><ul>
<li><a class="reference internal" href="#background-types-of-architectures">Background: Types of Architectures</a></li>
<li><a class="reference internal" href="#multiprocessor-architecture">Multiprocessor Architecture</a></li>
<li><a class="reference internal" href="#when-you-can-t-get-a-lock">When You Can&#8217;t Get a Lock</a><ul>
<li><a class="reference internal" href="#spinlocks">Spinlocks</a></li>
<li><a class="reference internal" href="#two-ways-to-build-spinlocks">Two Ways to Build Spinlocks</a><ul>
<li><a class="reference internal" href="#test-and-set">Test-and-Set</a></li>
<li><a class="reference internal" href="#test-and-test-and-set">Test-and-test-and-set</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#multiprocessor-architecture-part-2">Multiprocessor Architecture, part 2</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../index.html"
                        title="previous chapter">Spinlocks and Contention</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../part2/backoffandqueue.html"
                        title="next chapter">Solving the Mystery and Using Our Findings</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../part2/backoffandqueue.html" title="Solving the Mystery and Using Our Findings"
             >next</a> |</li>
        <li class="right" >
          <a href="../index.html" title="Spinlocks and Contention"
             >previous</a> |</li>
        <li><a href="../index.html">Spinlocks and Contention</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b1.
    </div>
  </body>
</html>