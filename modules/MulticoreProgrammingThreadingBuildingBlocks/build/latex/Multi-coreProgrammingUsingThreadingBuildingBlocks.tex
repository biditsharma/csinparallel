% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,openany,oneside]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{Multi-core Programming Using Threading Building Blocks}
\date{July 26, 2012}
\release{}
\author{CSInParallel Project}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\def\PYG@tok@gd{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\def\PYG@tok@gu{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\def\PYG@tok@gt{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.25,0.82}{##1}}}
\def\PYG@tok@gs{\let\PYG@bf=\textbf}
\def\PYG@tok@gr{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\def\PYG@tok@cm{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@vg{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@m{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@mh{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@cs{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\colorbox[rgb]{1.00,0.94,0.94}{##1}}}
\def\PYG@tok@ge{\let\PYG@it=\textit}
\def\PYG@tok@vc{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@il{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@go{\def\PYG@tc##1{\textcolor[rgb]{0.19,0.19,0.19}{##1}}}
\def\PYG@tok@cp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@gi{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\def\PYG@tok@gh{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\def\PYG@tok@ni{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\def\PYG@tok@nl{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\def\PYG@tok@nn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\def\PYG@tok@no{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\def\PYG@tok@na{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@nb{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@nc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\def\PYG@tok@nd{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\def\PYG@tok@ne{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@nf{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\def\PYG@tok@si{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\def\PYG@tok@s2{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@vi{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@nt{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\def\PYG@tok@nv{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@s1{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@gp{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\def\PYG@tok@sh{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@ow{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@sx{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\def\PYG@tok@bp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@c1{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@kc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@c{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@mf{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@err{\def\PYG@bc##1{\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{##1}}}
\def\PYG@tok@kd{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@ss{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\def\PYG@tok@sr{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\def\PYG@tok@mo{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@mi{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@kn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@o{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@kr{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@s{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@kp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@w{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\def\PYG@tok@kt{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\def\PYG@tok@sc{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@sb{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@k{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@se{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@sd{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Introduction}
\label{Introduction/Introduction:introduction}\label{Introduction/Introduction::doc}\label{Introduction/Introduction:multi-core-programming-using-threading-building-blocks}
Intel Corporation has set up a special remote system that allows faculty and students to work with computers with lots of cores, called the \emph{Manycore Testing Lab (MTL)}. In this lab, we will create a program that intentionally uses multi-core parallelism, upload and run it on the MTL, and explore the issues in parallelism and concurrency that arise.


\section{Requirements}
\label{Introduction/Introduction:requirements}
It is recommended that you work on a non-lab machine (preferably a personal laptop) for this lab; you can still use the lab computers in order to develop our multi-core program, but we need to connect to the Intel MTL system using a non-lab computer. This is because the Cisco VPN software for connecting to the MTL blocks all other network access, so we can't use it on the lab computers or it would interfere with all other uses of those computers.

If you choose to use your own computer for this lab, you will need the following materials:
\begin{itemize}
\item {} 
A C++ compiler, if you do not have one on your computer already.  GNU's gcc compiler is one such example, and is available on Windows, Mac OS, and Linux.

\item {} 
A text editor or program to write and save C++ programs

\item {} 
Cisco VPN client, which we will use to access the MTL. Instructions for installing Cisco VPN client for your machine is detailed in the next section.

\item {} 
A terminal. Linux and Mac OS have UNIX-based terminals by default. For Windows, you also need ssh and scp capabilities. Putty and Cygwin are two ways to get these capabilities. With \href{http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html}{Putty}, you'll need both \textbf{putty.exe} and \textbf{pscp.exe}. Ask for help if you need it.

\end{itemize}


\chapter{Preparing your machine for the lab}
\label{Preparement/Preparement:preparing-your-machine-for-the-lab}\label{Preparement/Preparement:putty}\label{Preparement/Preparement::doc}
\textbf{Carry the steps in this section before the lab, if possible, on a laptop you can bring with you to the lab session.}

The Cisco VPN client software is free, easy to install, easy to use, and does not interfere with your computer except while you are connected to the MTL. Here are download links (install before the lab if possible):
\begin{itemize}
\item {} 
\href{http://www.cs.stolaf.edu/pub/vpnclient-win-msi-5.0.06.0160-k9.exe}{Windows (2000,XP,Vista,7)}

Download the from this link and run the executable to install the Cisco VPN client.

\item {} 
\href{http://helpdesk.ugent.be/vpn/download/vpnclient-darwin-4.9.01.0080-universal-k9-5-10.dmg}{Mac OS 10.4 and later}

Download from this link, which creates a pseudodisk on your desktop, then open that pseudodisk and follow the instructions. (You can delete the pseudodisk when you're done.)

You can use a UNIX terminal window to access ssh and scp.

\item {} 
For Linux and other versions of Windows and Macintosh, you can see the \href{http://helpdesk.ugent.be/vpn/en/akkoord.php}{University of Ghent page} that these downloads were obtained from. Choose among the ``Cisco VPN clients without config file''.

\end{itemize}

Once you have installed the Cisco VPN client (and have ssh and scp installed), configure the Cisco VPN client to access the multicore testing lab, as follows.
\begin{enumerate}
\item {} 
Start up the Cisco VPN client.

\end{enumerate}
\begin{quote}

\begin{notice}{note}{Note:}
This is installed as a software application. \emph{Don't} look for it under system network connection options, like other VPN systems.
\end{notice}
\end{quote}
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
Create a new connection, with the following connection information:

\end{enumerate}
\begin{quote}
\begin{itemize}
\item {} 
\emph{Connection entry:} Choose a name, perhaps ``Intel MTL VPN''

\item {} 
\emph{Description:} Optional

\item {} 
\emph{Host:} \textbf{192.55.51.80}

\item {} 
Select \emph{Group Authentication} (probably the default)

\item {} 
\emph{Name} is \textbf{VPN2}

\item {} 
\emph{Password} is sent to you separately.

\end{itemize}

Save this connection to finish creating it.
\end{quote}
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
Now try connecting on your new VPN connection entry.

\end{enumerate}
\begin{itemize}
\item {} 
If this succeeds, you will find that \emph{none of your usual network services work}. For example, your browser won't be able to find any pages (thus, you'll have to use a different machine while you're connected to the MTL if you need to access network services).

\item {} 
If your new VPN connection fails, recheck the settings you entered, or seek help.

\end{itemize}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
Finally, disconnect from your new VPN connection entry. This will give you your usual network capabilities back, etc.

\end{enumerate}


\chapter{Intel's Threading Building Blocks (TBB)}
\label{TBB/TBB:intel-s-threading-building-blocks-tbb}\label{TBB/TBB::doc}\label{TBB/TBB:university-of-ghent-page}

\section{Introduction}
\label{TBB/TBB:introduction}
OpenMP works well for adding parallelism to loops in working sequential code, and it's available for C, C++, and Fortran languages on many platforms (including Linux, Windows, and Macintosh OS X). Older versions of OpenMP did not readily support non-loop parallelism or programming with concurrent data structures, but OpenMP version 3.0 (released May 2008) provides a task feature for programming such computations.

Intel's \href{http://threadingbuildingblocks.org/}{Threading Building Blocks (TBB)} provides an object-oriented approach to implementing parallel algorithms, for the C++ language (and any of the three platforms). Adding parallelism to existing code in TBB is somewhat more involved than in OpenMP, but is considerably less complicated than programming in a native threads package for a particular operating system. The forthcoming new standard for the C++ language is likely to include parallelism similar to TBB.


\section{For You To Do}
\label{TBB/TBB:threading-building-blocks-tbb}\label{TBB/TBB:for-you-to-do}

\subsection{Create the code}
\label{TBB/TBB:create-the-code}
Enter the following TBB program into a file \code{trap-tbb.cpp}. Or you can download the file \code{trap-tbb.cpp}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+cp}{\#}\PYG{c+cp}{include \textless{}iostream\textgreater{}}
\PYG{c+cp}{\#}\PYG{c+cp}{include \textless{}cmath\textgreater{}}
\PYG{k}{using} \PYG{k}{namespace} \PYG{n}{std}\PYG{p}{;}

\PYG{c+cp}{\#}\PYG{c+cp}{include "tbb}\PYG{c+cp}{/}\PYG{c+cp}{tbb.h"}
\PYG{k}{using} \PYG{k}{namespace} \PYG{n}{tbb}\PYG{p}{;}

\PYG{c+cm}{/* Demo program for TBB: computes trapezoidal approximation to an integral*/}

\PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{pi} \PYG{o}{=} \PYG{l+m+mf}{3.141592653589793238462643383079}\PYG{p}{;}

\PYG{k+kt}{double} \PYG{n}{f}\PYG{p}{(}\PYG{k+kt}{double} \PYG{n}{x}\PYG{p}{)}\PYG{p}{;}
     
\PYG{k}{class} \PYG{n+nc}{SumHeights} \PYG{p}{\PYGZob{}}
  \PYG{k+kt}{double} \PYG{k}{const} \PYG{n}{my\PYGZus{}a}\PYG{p}{;}
  \PYG{k+kt}{double} \PYG{k}{const} \PYG{n}{my\PYGZus{}h}\PYG{p}{;}
  \PYG{k+kt}{double} \PYG{o}{\&}\PYG{n}{my\PYGZus{}int}\PYG{p}{;}

\PYG{k}{public}\PYG{o}{:}
  \PYG{k+kt}{void} \PYG{k}{operator}\PYG{p}{(}\PYG{p}{)} \PYG{p}{(}\PYG{k}{const} \PYG{n}{blocked\PYGZus{}range}\PYG{o}{\textless{}}\PYG{n}{size\PYGZus{}t}\PYG{o}{\textgreater{}}\PYG{o}{\&} \PYG{n}{r}\PYG{p}{)} \PYG{k}{const} \PYG{p}{\PYGZob{}}
    \PYG{k}{for}\PYG{p}{(}\PYG{n}{size\PYGZus{}t} \PYG{n}{i} \PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i} \PYG{o}{!}\PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{end}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i}\PYG{o}{+}\PYG{o}{+}\PYG{p}{)} \PYG{p}{\PYGZob{}}
      \PYG{n}{my\PYGZus{}int} \PYG{o}{+}\PYG{o}{=} \PYG{n}{f}\PYG{p}{(}\PYG{n}{my\PYGZus{}a}\PYG{o}{+}\PYG{n}{i}\PYG{o}{*}\PYG{n}{my\PYGZus{}h}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}}
  
  \PYG{n}{SumHeights}\PYG{p}{(}\PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{a}\PYG{p}{,} \PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{h}\PYG{p}{,} \PYG{k+kt}{double} \PYG{o}{\&}\PYG{n}{integral}\PYG{p}{)} \PYG{o}{:} 
    \PYG{n}{my\PYGZus{}a}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}h}\PYG{p}{(}\PYG{n}{h}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}int}\PYG{p}{(}\PYG{n}{integral}\PYG{p}{)} 
  \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}

\PYG{k+kt}{int} \PYG{n}{main}\PYG{p}{(}\PYG{k+kt}{int} \PYG{n}{argc}\PYG{p}{,} \PYG{k+kt}{char}\PYG{o}{*}\PYG{o}{*} \PYG{n}{argv}\PYG{p}{)} \PYG{p}{\PYGZob{}}
   \PYG{c+cm}{/* Variables */}
   \PYG{k+kt}{double} \PYG{n}{a} \PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{b} \PYG{o}{=} \PYG{n}{pi}\PYG{p}{;}  \PYG{c+cm}{/* limits of integration */}\PYG{p}{;}
   \PYG{k+kt}{int} \PYG{n}{n} \PYG{o}{=} \PYG{l+m+mi}{1048576}\PYG{p}{;} \PYG{c+cm}{/* number of subdivisions = 2\PYGZca{}20 */}

   \PYG{k+kt}{double} \PYG{n}{h} \PYG{o}{=} \PYG{p}{(}\PYG{n}{b} \PYG{o}{-} \PYG{n}{a}\PYG{p}{)} \PYG{o}{/} \PYG{n}{n}\PYG{p}{;} \PYG{c+cm}{/* width of subdivision */}
   \PYG{k+kt}{double} \PYG{n}{integral}\PYG{p}{;} \PYG{c+cm}{/* accumulates answer */}
   
   \PYG{n}{integral} \PYG{o}{=} \PYG{p}{(}\PYG{n}{f}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)} \PYG{o}{+} \PYG{n}{f}\PYG{p}{(}\PYG{n}{b}\PYG{p}{)}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mf}{2.0}\PYG{p}{;}

   \PYG{n}{parallel\PYGZus{}for}\PYG{p}{(}\PYG{n}{blocked\PYGZus{}range}\PYG{o}{\textless{}}\PYG{n}{size\PYGZus{}t}\PYG{o}{\textgreater{}}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{n}\PYG{p}{)}\PYG{p}{,} \PYG{n}{SumHeights}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{h}\PYG{p}{,} \PYG{n}{integral}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
   
   \PYG{n}{integral} \PYG{o}{=} \PYG{n}{integral} \PYG{o}{*} \PYG{n}{h}\PYG{p}{;}
   \PYG{n}{cout} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{With n = }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{n} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ trapezoids, our estimate of the integral}\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}}
     \PYG{l+s}{"}\PYG{l+s}{ from }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{a} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ to }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{b} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ is }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{integral} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{endl}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
    
\PYG{k+kt}{double} \PYG{n}{f}\PYG{p}{(}\PYG{k+kt}{double} \PYG{n}{x}\PYG{p}{)} \PYG{p}{\PYGZob{}}

   \PYG{k}{return} \PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}


\subsection{Study this code carefully}
\label{TBB/TBB:study-this-code-carefully}
Observe the following:

This program does \emph{not} use a command-line argument (and the \code{cstdlib} library is not needed). Unlike OpenMP, TBB does not provide a simple way to request a particular number of threads. Instead, the TBB system chooses a number of threads to use automatically. (OpenMP will also make such a selection for you if you do not specify the number of threads to use.)

The following lines prepare for using TBB.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+cp}{\#}\PYG{c+cp}{include "tbb}\PYG{c+cp}{/}\PYG{c+cp}{tbb.h"}
\PYG{k}{using} \PYG{k}{namespace} \PYG{n}{tbb}\PYG{p}{;}
\end{Verbatim}

Recall that in the OpenMP code, we parallelized the loop below by adding a pragma just before that for loop.

\begin{Verbatim}[commandchars=\\\{\}]
for(i = 1; i \textless{} n; i++) \PYGZob{}
   integral += f(a+i*h);
 \PYGZcb{}
\end{Verbatim}

In order to program a comparable computation in TBB, we create a class \code{SumHeights} whose method \code{operator()} contains the following loop:

\begin{Verbatim}[commandchars=\\\{\}]
    \PYG{k}{for}\PYG{p}{(}\PYG{n}{size\PYGZus{}t} \PYG{n}{i} \PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i} \PYG{o}{!}\PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{end}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i}\PYG{o}{+}\PYG{o}{+}\PYG{p}{)} \PYG{p}{\PYGZob{}}
      \PYG{n}{my\PYGZus{}int} \PYG{o}{+}\PYG{o}{=} \PYG{n}{f}\PYG{p}{(}\PYG{n}{my\PYGZus{}a}\PYG{o}{+}\PYG{n}{i}\PYG{o}{*}\PYG{n}{my\PYGZus{}h}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
\end{Verbatim}

Observe that the forms of the two loops indicate the same iterative computation, if one matches 1 to \code{r.begin()}, \code{n} to \code{r.end()} and \code{integral}, \code{a}, and h to \code{SumHeights} state variables \code{my\_int}, \code{my\_a}, and \code{my\_h}.  One way to describe this relationship is to say that the class \code{SumHeights} is a ``wrapper''     around its loop.

The class \code{SumHeights} defines \code{operator()}, which means that an object of type \code{SumHeights} can be called using function-call syntax. Since \code{operator()} is defined here with one argument, this means we can cause the for loop to execute using a call \code{sh(range)}, where \code{sh} is an object of type \code{SumHeights} and \code{range} is an appropriate argument.
\begin{enumerate}
\item {} 
Note that \code{operator()} is a \code{const} method (indicated by the const after \code{)} and before \code{\{} ), which means that it is permitted to call \code{sh(range)} with a \code{const} object sh.

\item {} 
The argument \code{r} of \code{operator()} indicates the \emph{range} of the loop, i.e., the starting and ending values for the loop control variable.

\item {} 
The loop control variable \code{i} has type \code{int} in the OpenMP implementation, but type \code{size\_t} in the TBB implementation. \code{size\_t} is an integer type, which may be equivalent to \code{int}, \code{long}, or another integer type depending on implementation.

\item {} 
The range \code{r} has the type \code{blocked\_range\textless{}size\_t\textgreater{}}. This is a \emph{templated type} built over the \code{size\_t} type. There could be \code{blocked\_range} types built over other types, as well, e.g., \code{int} or \code{long}.

\end{enumerate}

The constructor \code{SumHeights()} makes local copies \code{my\_a}, etc., of variables \code{a}, etc., in \code{main()}, enabling values in \code{main()} to be used within the class \code{SumHeights}.

The call to \code{parallel\_for} in \code{main()} automatically subdivides (or chunks) the range \code{r} for multi-threaded parallel computation. \code{parallel\_for} expects a range in its first argument, and an object with a method \code{operator()} having one range argument in its second argument.

The variable \code{integral} is passed by reference in the constructor \code{SumHeights()} in an effort to use that memory location \code{integral} as an accumulator during the parallelized computation.

The constructor initializes the state variables \code{my\_a}, \code{my\_h}, and \code{my\_int} using \emph{colon initializers}. In the constructor definition

\begin{Verbatim}[commandchars=\\\{\}]
  \PYG{n}{SumHeights}\PYG{p}{(}\PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{a}\PYG{p}{,} \PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{h}\PYG{p}{,} \PYG{k+kt}{double} \PYG{o}{\&}\PYG{n}{integral}\PYG{p}{)} \PYG{o}{:} 
    \PYG{n}{my\PYGZus{}a}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}h}\PYG{p}{(}\PYG{n}{h}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}int}\PYG{p}{(}\PYG{n}{integral}\PYG{p}{)} 
  \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\end{Verbatim}

The expression \code{my\_a(a)} located after the colon : and before the curly bracket \code{\{} has the same effect as an assignment

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{my\PYGZus{}a} \PYG{o}{=} \PYG{n}{a}\PYG{p}{;}
\end{Verbatim}

would if it occurred \emph{between} the curly brackets. Colon initialization is optional for the state variables \code{my\_a} and \code{my\_h}, but it is required for the state variable \code{my\_int}, because that state variable was defined using a reference type.

\begin{notice}{note}{Note:}
Can you detect any problems in this code?
\end{notice}


\subsection{Execute this code}
\label{TBB/TBB:execute-this-code}
For this lab, we will run this TBB program on the MTL.

First, if necessary, copy the program file you created to a local machine for connecting to MTL, e.g., your laptop. You will need to use a ‘terminal’ on Macs or ‘Putty’ on PCs.  If you are off campus, you will need to ssh into a machine on your campus before then logging into the MTL machine at Intel’s headquarters in Oregon.

You can login to the MTL computer, as follows

\begin{Verbatim}[commandchars=\\\{\}]
laptop\% ssh accountname@192.55.51.81
\end{Verbatim}

Use one of the student account usernames provided to you, together with the password distributed to the class.

Next, copy your program from your laptop or local linux machine to the MTL machine. One way to do this is to use another window (to keep for copying your code), then enter the following command from the directory where your code is located:

\begin{Verbatim}[commandchars=\\\{\}]
scp trap-tbb.cpp accountname@192.55.51.81:
\end{Verbatim}

On the remote MTL system, execute the following command, which sets up environment variables for compiling with TBB:

\begin{Verbatim}[commandchars=\\\{\}]
source/opt/intel/Compiler/11.1/056/tbb/bin/tbbvars.sh intel64
\end{Verbatim}

The \code{intel64} command-line argument prepares for 64-bit compilation.

After making this copy, login into the MTL machine 192.55.51.81 in another window.

To compile your program that was copied in a prior step, issue this command:

\begin{Verbatim}[commandchars=\\\{\}]
192.55.51.81\% g++ -o trap-tbb trap-tbb.cpp -ltbb\_debug
\end{Verbatim}

\begin{notice}{note}{Note:}
You can use \code{-ltbb} instead of \code{-ltbb\_debug} for a production version of the library instead of one with debugging hooks.
\end{notice}

Now run your program with the following command:

\begin{Verbatim}[commandchars=\\\{\}]
192.55.51.81\% ./trap-tbb
\end{Verbatim}

The result is significantly less than 2! Can you think of an explanation for the answer being so far off?

Also run several time tests of your program

\begin{Verbatim}[commandchars=\\\{\}]
192.55.51.81\% time ./trap-tbb
\end{Verbatim}

What do you observe in these time tests? How do the times compare to timed runs of \code{trap-omp} for various thread sizes?


\chapter{TBB, multiple threads, and reduction}
\label{MultipleThreadsAndReduction/MultipleThreadsAndReduction:tbb-multiple-threads-and-reduction}\label{MultipleThreadsAndReduction/MultipleThreadsAndReduction::doc}
The code above for a TBB trapezoidal computation produces an incorrect answer if there are multiple threads, because each thread attempts to update the shared variable \code{integral} without any mechanism to avoid one thread from overwriting the results produced by another thread.  We will solve this issue using a \emph{reduction}, in which results will be computed in \emph{local} variables for each thread, then those local results added together at the end.
\begin{enumerate}
\item {} 
To do the reduction in TBB, we will use the \code{parallel\_reduce} call instead of the \code{parallel\_for} call, and will use a modified class \code{SumHeights2}.

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+cp}{\#}\PYG{c+cp}{include \textless{}iostream\textgreater{}}
\PYG{c+cp}{\#}\PYG{c+cp}{include \textless{}cmath\textgreater{}}
\PYG{k}{using} \PYG{k}{namespace} \PYG{n}{std}\PYG{p}{;}

\PYG{c+cp}{\#}\PYG{c+cp}{include "tbb}\PYG{c+cp}{/}\PYG{c+cp}{tbb.h"}
\PYG{k}{using} \PYG{k}{namespace} \PYG{n}{tbb}\PYG{p}{;}

\PYG{c+cm}{/* Demo program for TBB: computes trapezoidal approximation to an integral*/}

\PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{pi} \PYG{o}{=} \PYG{l+m+mf}{3.141592653589793238462643383079}\PYG{p}{;}

\PYG{k+kt}{double} \PYG{n}{f}\PYG{p}{(}\PYG{k+kt}{double} \PYG{n}{x}\PYG{p}{)}\PYG{p}{;}
     
\PYG{k}{class} \PYG{n+nc}{SumHeights2} \PYG{p}{\PYGZob{}}
  \PYG{k+kt}{double} \PYG{k}{const} \PYG{n}{my\PYGZus{}a}\PYG{p}{;}
  \PYG{k+kt}{double} \PYG{k}{const} \PYG{n}{my\PYGZus{}h}\PYG{p}{;}

\PYG{k}{public}\PYG{o}{:}
  \PYG{k+kt}{double} \PYG{n}{my\PYGZus{}int}\PYG{p}{;}

  \PYG{k+kt}{void} \PYG{k}{operator}\PYG{p}{(}\PYG{p}{)} \PYG{p}{(}\PYG{k}{const} \PYG{n}{blocked\PYGZus{}range}\PYG{o}{\textless{}}\PYG{n}{size\PYGZus{}t}\PYG{o}{\textgreater{}}\PYG{o}{\&} \PYG{n}{r}\PYG{p}{)} \PYG{p}{\PYGZob{}}
    \PYG{k+kt}{double} \PYG{n}{a2} \PYG{o}{=} \PYG{n}{my\PYGZus{}a}\PYG{p}{;}
    \PYG{k+kt}{double} \PYG{n}{h2} \PYG{o}{=} \PYG{n}{my\PYGZus{}h}\PYG{p}{;}
    \PYG{k+kt}{double} \PYG{n}{int2} \PYG{o}{=} \PYG{n}{my\PYGZus{}int}\PYG{p}{;}
    \PYG{n}{size\PYGZus{}t} \PYG{n}{end} \PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{end}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{for}\PYG{p}{(}\PYG{n}{size\PYGZus{}t} \PYG{n}{i} \PYG{o}{=} \PYG{n}{r}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i} \PYG{o}{!}\PYG{o}{=} \PYG{n}{end}\PYG{p}{;} \PYG{n}{i}\PYG{o}{+}\PYG{o}{+}\PYG{p}{)} \PYG{p}{\PYGZob{}}
      \PYG{n}{int2} \PYG{o}{+}\PYG{o}{=} \PYG{n}{f}\PYG{p}{(}\PYG{n}{a2}\PYG{o}{+}\PYG{n}{i}\PYG{o}{*}\PYG{n}{h2}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
    \PYG{n}{my\PYGZus{}int} \PYG{o}{=} \PYG{n}{int2}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
  
  \PYG{n}{SumHeights2}\PYG{p}{(}\PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{a}\PYG{p}{,} \PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{h}\PYG{p}{,} \PYG{k}{const} \PYG{k+kt}{double} \PYG{n}{integral}\PYG{p}{)} \PYG{o}{:} 
    \PYG{n}{my\PYGZus{}a}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}h}\PYG{p}{(}\PYG{n}{h}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}int}\PYG{p}{(}\PYG{n}{integral}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}

  \PYG{n}{SumHeights2}\PYG{p}{(}\PYG{n}{SumHeights2} \PYG{o}{\&}\PYG{n}{x}\PYG{p}{,} \PYG{n}{split}\PYG{p}{)} \PYG{o}{:} 
    \PYG{n}{my\PYGZus{}a}\PYG{p}{(}\PYG{n}{x}\PYG{p}{.}\PYG{n}{my\PYGZus{}a}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}h}\PYG{p}{(}\PYG{n}{x}\PYG{p}{.}\PYG{n}{my\PYGZus{}h}\PYG{p}{)}\PYG{p}{,} \PYG{n}{my\PYGZus{}int}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}

  \PYG{k+kt}{void} \PYG{n}{join}\PYG{p}{(} \PYG{k}{const} \PYG{n}{SumHeights2} \PYG{o}{\&}\PYG{n}{y}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{n}{my\PYGZus{}int} \PYG{o}{+}\PYG{o}{=} \PYG{n}{y}\PYG{p}{.}\PYG{n}{my\PYGZus{}int}\PYG{p}{;} \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}

\PYG{k+kt}{int} \PYG{n}{main}\PYG{p}{(}\PYG{k+kt}{int} \PYG{n}{argc}\PYG{p}{,} \PYG{k+kt}{char}\PYG{o}{*}\PYG{o}{*} \PYG{n}{argv}\PYG{p}{)} \PYG{p}{\PYGZob{}}
   \PYG{c+cm}{/* Variables */}
   \PYG{k+kt}{double} \PYG{n}{a} \PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{b} \PYG{o}{=} \PYG{n}{pi}\PYG{p}{;}  \PYG{c+cm}{/* limits of integration */}\PYG{p}{;}
   \PYG{k+kt}{int} \PYG{n}{n} \PYG{o}{=} \PYG{l+m+mi}{1048576}\PYG{p}{;} \PYG{c+cm}{/* number of subdivisions = 2\PYGZca{}20 */}

   \PYG{k+kt}{double} \PYG{n}{h} \PYG{o}{=} \PYG{p}{(}\PYG{n}{b} \PYG{o}{-} \PYG{n}{a}\PYG{p}{)} \PYG{o}{/} \PYG{n}{n}\PYG{p}{;} \PYG{c+cm}{/* width of subdivision */}
   \PYG{k+kt}{double} \PYG{n}{integral}\PYG{p}{;} \PYG{c+cm}{/* accumulates answer */}
   
   \PYG{n}{integral} \PYG{o}{=} \PYG{p}{(}\PYG{n}{f}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)} \PYG{o}{+} \PYG{n}{f}\PYG{p}{(}\PYG{n}{b}\PYG{p}{)}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mf}{2.0}\PYG{p}{;}

   \PYG{n}{SumHeights2} \PYG{n}{sh2}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{h}\PYG{p}{,} \PYG{n}{integral}\PYG{p}{)}\PYG{p}{;}
   \PYG{n}{parallel\PYGZus{}reduce}\PYG{p}{(}\PYG{n}{blocked\PYGZus{}range}\PYG{o}{\textless{}}\PYG{n}{size\PYGZus{}t}\PYG{o}{\textgreater{}}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{n}\PYG{p}{)}\PYG{p}{,} \PYG{n}{sh2}\PYG{p}{)}\PYG{p}{;}
   \PYG{n}{integral} \PYG{o}{+}\PYG{o}{=} \PYG{n}{sh2}\PYG{p}{.}\PYG{n}{my\PYGZus{}int}\PYG{p}{;}
   
   \PYG{n}{integral} \PYG{o}{=} \PYG{n}{integral} \PYG{o}{*} \PYG{n}{h}\PYG{p}{;}
   \PYG{n}{cout} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{With n = }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{n} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ trapezoids, our estimate of the integral}\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}}
     \PYG{l+s}{"}\PYG{l+s}{ from }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{a} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ to }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{b} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{l+s}{"}\PYG{l+s}{ is }\PYG{l+s}{"} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{integral} \PYG{o}{\textless{}}\PYG{o}{\textless{}} \PYG{n}{endl}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
    
\PYG{k+kt}{double} \PYG{n}{f}\PYG{p}{(}\PYG{k+kt}{double} \PYG{n}{x}\PYG{p}{)} \PYG{p}{\PYGZob{}}

   \PYG{k}{return} \PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Comments}] \leavevmode\begin{itemize}
\item {} 
The class \code{SumHeights2} handles the variable \code{my\_int} differently than the class \code{SumHeights} does. Instead of \code{SumHeights}`s misguided attempt to share main()'s memory location \code{integral} through reference types, the new class \code{SumHeights2} allocates a new separate (state) variable location my\_int for each object of type \code{SumHeights2} (by avoiding reference types).

\item {} 
Also, \code{my\_int} is a \code{public} state variable in \code{SumHeights2}, instead of the default \code{private} visibility in the prior class \code{SumHeights}. This makes it possible for a method of a \code{SumHeights2} object to compute a value and store that value in \code{my\_int}, then for another part of the code to access that computed value through that public state variable \code{my\_int}. (Alternatively, we could have made \code{my\_int} private like the other state variables, and added a ``getter'' method \code{get\_my\_int()} to retrieve that computed value.)

\item {} 
The \code{operator()} definitions in the two classes differ in several ways.
\begin{enumerate}
\item {} 
The code for the new class's operator \code{SumHeights2::operator()} begins my making local copies \code{a2}, \code{h2}, and \code{int2} of the variables \code{my\_a}, \code{my\_h}, and \code{my\_int}, and also storing the (unchanging) value of \code{r.end()} in another local variable. These local variable assignments are not necessary for the logical correctness of the code. Instead, they make it possible for the compiler to produce a more efficient computations. With this help, the compiler can realize that it's safe to use \emph{registers} to implement those variables \emph{instead of memory locations}, which would lead to faster access to those values.

\item {} 
The loop is rewritten to use these local variables, but otherwise represents the same computation as in the previous \code{SumHeights::operator()}.

\item {} 
\emph{After} the loop, the local variable \code{int2} is assigned to the state variable \code{my\_int}, in order to deliver the sum for this thread's subdivision (chunk) of the summation range.

\item {} 
\code{SumHeights2::operator()} is \emph{not} a \code{const} method. This means it's not safe for \code{const} objects to call this method -- they will be changed. In this case, the change is that \code{my\_int} is changed when \code{operator()} is called.

\end{enumerate}

\item {} 
The three-argument constructor for \code{SumHeights} is the same as the three-argument constructor for \code{SumHeights2}, except for the handling of the third argument \code{integral} (discussed above).

\item {} 
However, the class \code{SumHeights2} has an additional constructor and an additional method \code{join()}.
\begin{enumerate}
\item {} 
The second constructor is called a \emph{split constructor}. This constructor will be used to construct new instances of \code{SumHeights2} for additional threads brought into the summation computation.

\item {} 
The method \code{join()} is used to add the partial sum from one thread's computation to a running sum -- i.e., to perform the reduction operation.

\end{enumerate}

\item {} 
Here is an overview description of the parallel computation for this program.
\begin{enumerate}
\item {} 
An object \code{sh2} is allocated, using the three-argument constructor for \code{SumHeights2}.

\item {} 
The call to \code{parallel\_reduce()} in \code{main()} performs \code{sh2}`s \code{operator()} over the range 1 to n by subdividing (i.e., chunking) that range and assigning a thread to perform the trapezoidal sum for each chunk.

\item {} 
Each of those threads creates its own \code{SumHeights2} object using the splitting constructor.

\end{enumerate}
\begin{itemize}
\item {} 
The thread first calls that splitting object's \code{operator()} with that thread's range chunk to compute a partial sum.

\item {} 
Then, the thread calls \code{sh2.join()} with that splitting object as the argument, in order to add its partial sum to \code{sh2}`s accumulator \code{sh2.my\_int}.

\end{itemize}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
After all range chunks have been processed, \code{parallel\_reduce()} finishes, leaving the final answer in the \code{public} state variable \code{sh2.my\_int}.

\end{enumerate}
\begin{itemize}
\item {} 
The splitting constructor for \code{SumHeights2} has a dummy argument of type \code{split} (defined by the TBB library), because without that extra argument, there would be no way for a compiler to tell the difference between a call to that splitting constructor and a call to \code{SumHeight2}`s copy constructor.

\end{itemize}

\end{itemize}

\end{description}\end{quote}
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
Enter the program above, using the filename \code{trap-tbb2.cpp}. Or you can download the file \code{trap-tbb2.cpp}

You can enter it on a lab machine, but then you'd have to disconnect Cisco VPN on your local machine (e.g., your laptop), \code{scp} the new file to your local machine, reconnect Cisco VPN, and \code{scp} to the MTL machine in order to transfer it to the MTL system.

\item {} 
Compile and test your \code{trap-tbb2} program on the MTL. Does it now produce the correct answer of 2 for the trapezoidal approximation?

\item {} 
Also time the performance of runs of this revised program, and compare to the time performance of runs of the prior program \code{trap-tbb}.

\end{enumerate}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
