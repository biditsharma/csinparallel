

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Activities &mdash; Heterogeneous Computing</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Heterogeneous Computing" href="../index.html" />
    <link rel="next" title="The Three Musketeers" href="../TheThreeMusketeers/TheThreeMusketeers.html" />
    <link rel="prev" title="Coding and Compiling a Heterogeneous Program" href="../CodingAndCompiling/CodingAndCompiling.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../TheThreeMusketeers/TheThreeMusketeers.html" title="The Three Musketeers"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../CodingAndCompiling/CodingAndCompiling.html" title="Coding and Compiling a Heterogeneous Program"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Heterogeneous Computing</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="activities">
<h1>Activities<a class="headerlink" href="#activities" title="Permalink to this headline">¶</a></h1>
<p>In this chapter, we are going to look at two problems, one is vector-matrix multiplication, and the other is matrix-matrix multiplication. We chose these problems because they are relatively easy to decompose, and not complicated.</p>
<div class="section" id="activity-2-vector-matrix-multiplication">
<h2>Activity 2: Vector Matrix Multiplication<a class="headerlink" href="#activity-2-vector-matrix-multiplication" title="Permalink to this headline">¶</a></h2>
<p>In this activity, we are going to compute vector-matrix multiplication in hybrid environment MPI and CUDA. You might already see this problem before in the MPI module. If so, it will be not much different. The basic idea is we would like to split the rows of the matrix, and ask the master to send some rows of the matrix and entire input vector to each worker. We then ask each worker to receive messages from the master, and each worker will call the CUDA function to do computation on their own GPU. Basically, on the GPU each thread will take care of a multiplication between an element of the matrix, and an element of the vector. This obviously would speed up our computation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">Comments on CUDA program:</th></tr>
<tr class="field-odd field"><td>&nbsp;</td><td class="field-body"><ul class="first">
<li><p class="first">First let&#8217;s look at the kernel function in the CUDA program. We use one thread to for one row of the matrix in our vector matrix multiplication. We also use linear array instead of two dimensional array.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* kernel function for computation on the GPU */</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">kernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="kt">int</span> <span class="n">block_size</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">entry</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">entry</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">tid</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="n">y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">entry</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Then we need to have a function that calls the kernel function on the host. This function is to allocate memory for the matrix and vector on the device, copy matrix and vector from host to device, compute the vector matrix multiplication, and copy the result vector from device to the host. This function will be called in the MPI program. Your task is to call kernel function at <strong>TO DO</strong>.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* function on the host, CPU */</span>
<span class="k">extern</span> <span class="s">&quot;C&quot;</span> <span class="kt">void</span> <span class="n">run_kernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="kt">int</span> <span class="n">block_size</span><span class="p">)</span> <span class="p">{</span>

        <span class="cm">/* the size of the matrix and the vector */</span>
        <span class="kt">int</span> <span class="n">matrix_size</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">vector_size</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span><span class="p">;</span>

        <span class="cm">/* Pointes array on GPU */</span>
        <span class="kt">int</span> <span class="o">*</span><span class="n">dev_A</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_x</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_y</span><span class="p">;</span>

        <span class="cm">/* Allocate memory on GPU */</span>
        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_A</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">);</span>
        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_x</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">);</span>
        <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_y</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">);</span>

        <span class="cm">/* Copy matrix and vector from CPU to GPU */</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_A</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

        <span class="cm">/* Initializing the grid size and block size */</span>
        <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="n">width</span><span class="o">/</span><span class="n">block_size</span><span class="p">,</span> <span class="n">width</span><span class="o">/</span><span class="n">block_size</span><span class="p">);</span>
        <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">);</span>

        <span class="cm">/* Running the kernel function */</span>
        <span class="c1">// TO DO</span>
        <span class="c1">// call the kernel function</span>
        <span class="c1">// end TO DO</span>

        <span class="cm">/* Copy the output vector from GPU to CPU */</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dev_y</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

        <span class="cm">/* Free memory on GPU */</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_A</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_x</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_y</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Comments on MPI program:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body"><ul class="first last">
<li><p class="first">Now we can look at our MPI program with an addition of a CUDA function. First we need to initialize the MPI execution environment, define the size of MPI_COMM_WORLD, and give a unique rank to each process. Then we ask the master to initialize the input matrix and vector, divide the matrix by row, and send their pieces and the entire vector to each worker. Your task is to complete code at <strong>TO DO</strong>:</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* Initialize MPI execution environment */</span>
<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
<span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">nprocs</span><span class="p">);</span>

<span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">len</span><span class="p">);</span>

<span class="cm">/******************************* Master ***************************/</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="cm">/* Initialize Matrix and Vector */</span>
        <span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ROWS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">vector</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
                <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">COLS</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                        <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
                <span class="p">}</span>
        <span class="p">}</span>

        <span class="n">numworkers</span> <span class="o">=</span> <span class="n">nprocs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>

        <span class="cm">/* divide the number of rows for each worker */</span>
        <span class="n">averow</span> <span class="o">=</span> <span class="n">ROWS</span><span class="o">/</span><span class="n">numworkers</span><span class="p">;</span>
        <span class="n">extra</span> <span class="o">=</span> <span class="n">ROWS</span><span class="o">%</span><span class="n">numworkers</span><span class="p">;</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_MASTER</span><span class="p">;</span>

        <span class="cm">/* Master sends smaller task to each worker */</span>
        <span class="k">for</span><span class="p">(</span><span class="n">dest</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">dest</span> <span class="o">&lt;=</span> <span class="n">numworkers</span><span class="p">;</span> <span class="n">dest</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">rows</span> <span class="o">=</span> <span class="p">(</span><span class="n">dest</span> <span class="o">&lt;=</span> <span class="n">extra</span><span class="p">)</span> <span class="o">?</span> <span class="n">averow</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">:</span> <span class="n">averow</span><span class="p">;</span>

                <span class="c1">// TO DO</span>
                <span class="c1">// send each piece of matrix and entire vector to each worker</span>
                <span class="c1">// end TO DO</span>

                <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Master sent elements %d to %d to rank %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span><span class="p">,</span> <span class="n">dest</span><span class="p">);</span>
                <span class="n">offset</span> <span class="o">+=</span> <span class="n">rows</span><span class="p">;</span>
        <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">We need to ask all workers to receive the messages sent from the master. Then we want each worker to call the CUDA function to compute their vector matrix multiplication. After having computed their multiplications, each worker needs to send their result back to the master. Please complete the following code at <strong>TO DO</strong>.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/************************************** Workers *************************************/</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_MASTER</span><span class="p">;</span>
        <span class="cm">/* Each worker receives messages sent from the master*/</span>

        <span class="c1">// TO DO</span>
        <span class="c1">// receive each piece of the matrix and vector sent from master</span>
        <span class="c1">// end TO DO</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Worker rank %d, %s receives the messages</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>

        <span class="cm">/* use CUDA function to compute the the vector-matrix multiplication for each worker */</span>
        <span class="c1">// TO DO</span>
        <span class="c1">// call CUDA function</span>
        <span class="c1">// end TO DO</span>

        <span class="cm">/* Each worker sends the result back to the master */</span>
        <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_WORKER</span><span class="p">;</span>
        <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">result</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Worker rank %d, %s sends the result to master </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Finally, we need to ask the master to receive the result vector sent from each worker, and prints the result vector.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* Master receives the output from each worker*/</span>
<span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_WORKER</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">numworkers</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">source</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span><span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">result</span><span class="p">[</span><span class="n">offset</span><span class="p">],</span> <span class="n">rows</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Received results from task %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/* Master prints results */</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ROWS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;The element of output vector is: %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Download the source code to do your activity:</dt>
<dd><p class="first"><a class="reference download internal" href="../_downloads/vec_matrix_mul_todo.cu"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">CUDA</span> <span class="pre">program</span></tt></a></p>
<p class="last"><a class="reference download internal" href="../_downloads/vec_matrix_mul_todo.c"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">MPI</span> <span class="pre">program</span></tt></a></p>
</dd>
<dt>Download the entire source code:</dt>
<dd><p class="first"><a class="reference download internal" href="../_downloads/vec_matrix_mul.cu"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">CUDA</span> <span class="pre">program</span></tt></a></p>
<p class="last"><a class="reference download internal" href="../_downloads/vec_matrix_mul.c"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">MPI</span> <span class="pre">program</span></tt></a></p>
</dd>
</dl>
</div>
<div class="section" id="activity-3-matrix-multiplication">
<h2>Activity 3: Matrix Multiplication<a class="headerlink" href="#activity-3-matrix-multiplication" title="Permalink to this headline">¶</a></h2>
<p>In this activity, we are going to compute matrix-matrix multiplication in hybrid environment MPI and CUDA. The basic idea is we want to split the rows of the first matrix, and ask the master to send some rows of the first matrix and the entire second matrix to each worker. We then ask each worker to receive messages sent from the master, and each worker will call the CUDA function to do computation on their own GPU. On the GPU each thread will take care of a multiplication between an element of the first matrix, and an element of the second matrix.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is not the most efficient method of doing matrix-matrix multiplication by using CUDA and MPI because when the second matrix gets too large, a progammer may not be able to send it to each worker. Furthermore, a programmer can improve the kernel function to be more effective by using the shared memory archeticture in the GPU.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">Comments on CUDA Program:</th></tr>
<tr class="field-odd field"><td>&nbsp;</td><td class="field-body"><ul class="first">
<li><p class="first">First let&#8217;s look at the kernel function in the CUDA program.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* kernel function */</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">MatrixKernel</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">dM</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">dN</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">dP</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>

        <span class="cm">/* calculate the row index of the dP element and M */</span>
        <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
        <span class="cm">/* calculate the column index of dP element and N */</span>
        <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

        <span class="kt">float</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="mf">0.0f</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="kt">float</span> <span class="n">M_elem</span> <span class="o">=</span> <span class="n">dM</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
                <span class="kt">float</span> <span class="n">N_elem</span> <span class="o">=</span> <span class="n">dN</span><span class="p">[</span><span class="n">k</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>
                <span class="n">pvalue</span> <span class="o">+=</span> <span class="n">M_elem</span> <span class="o">*</span> <span class="n">N_elem</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">dP</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pvalue</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">We use 2-dimensional blocks and threads for matrices. Each thread calculate an element of the result matrix.</p>
</li>
<li><p class="first">Then we need to have a function that calls the kernel function on the host. This function is to allocate memory for the matrices on the device, copy matrices from host to device, compute the matrix multiplication, and copy the result matrix from device to the host. This function will be called in the MPI program. Your task is to call kernel function at <strong>TO DO</strong>.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* function that you will call in mpi code */</span>
<span class="k">extern</span> <span class="s">&quot;C&quot;</span> <span class="kt">void</span> <span class="n">MatrixMul</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">N</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">P</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="kt">int</span> <span class="n">block_size</span><span class="p">)</span> <span class="p">{</span>

        <span class="kt">int</span> <span class="n">matrix_size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
        <span class="kt">float</span> <span class="o">*</span><span class="n">dM</span><span class="p">,</span> <span class="o">*</span><span class="n">dN</span><span class="p">,</span> <span class="o">*</span><span class="n">dP</span><span class="p">;</span>

        <span class="c1">// Allocate and Load M and N to device memory</span>
        <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dM</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">);</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dM</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

        <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dN</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">);</span>
        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dN</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

        <span class="c1">// Allocate P on device</span>
        <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dP</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">);</span>

        <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="n">width</span><span class="o">/</span><span class="n">block_size</span><span class="p">,</span> <span class="n">width</span><span class="o">/</span><span class="n">block_size</span><span class="p">);</span>
        <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">);</span>

        <span class="c1">// TO DO</span>
        <span class="c1">// call the kernel function</span>
        <span class="c1">// end TO DO</span>

        <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">dP</span><span class="p">,</span> <span class="n">matrix_size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dP</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dM</span><span class="p">);</span>
        <span class="n">cudaFree</span><span class="p">(</span><span class="n">dN</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Comments on MPI Program:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body"><ul class="first last">
<li><p class="first">Now we can look at the MPI program. This MPI program is a revised version of the Matrix Mutiplication MPI program that was written by Blaise Barney. First we need to initialize the MPI execution environment, define the size of MPI_COMM_WORLD, and give a unique rank to each process. Then we ask the master to initialize the input matrices, divide these matrices, and send their pieces to each worker.</p>
<div class="highlight-c"><div class="highlight"><pre>    <span class="cm">/**************************** master task ************************************/</span>
<span class="k">if</span> <span class="p">(</span><span class="n">taskid</span> <span class="o">==</span> <span class="n">MASTER</span><span class="p">)</span> <span class="p">{</span>

            <span class="cm">/* Initializing both matrices on master node */</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ROW_A</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">COL_A</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
                            <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">COL_A</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">COL_B</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
                            <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

            <span class="cm">/* Computing the average row and extra row for each process */</span>
            <span class="n">averow</span> <span class="o">=</span> <span class="n">ROW_A</span><span class="o">/</span><span class="n">numworkers</span><span class="p">;</span>
            <span class="n">extra</span> <span class="o">=</span> <span class="n">ROW_A</span><span class="o">%</span><span class="n">numworkers</span><span class="p">;</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
            <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_MASTER</span><span class="p">;</span>

            <span class="cm">/* Distributing the task to each worker */</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">dest</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">dest</span> <span class="o">&lt;=</span> <span class="n">numworkers</span><span class="p">;</span> <span class="n">dest</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">rows</span> <span class="o">=</span> <span class="p">(</span><span class="n">dest</span> <span class="o">&lt;=</span> <span class="n">extra</span><span class="p">)</span> <span class="o">?</span> <span class="n">averow</span><span class="o">+</span><span class="mi">1</span> <span class="o">:</span> <span class="n">averow</span><span class="p">;</span>
                    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Sending %d rows to task %d offset = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">offset</span><span class="p">);</span>

                    <span class="c1">// TO DO</span>
                    <span class="c1">// send some rows of first matrix and entire second matrix to each worker</span>
                    <span class="c1">// end TO DO</span>

                    <span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span><span class="p">;</span>
            <span class="p">}</span>
    <span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">We need to ask all workers to receive the messages sent from the master. Then we want each worker to call the CUDA function to compute their matrix multiplication. After having computed their multiplications, each worker needs to send their result back to the master. Please complete the following code at <strong>TO DO</strong>.:</p>
<div class="highlight-c"><div class="highlight"><pre>    <span class="cm">/**************************** worker task ************************************/</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">taskid</span> <span class="o">&gt;</span> <span class="n">MASTER</span><span class="p">)</span> <span class="p">{</span>

            <span class="cm">/* Each receives task from master*/</span>
            <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_MASTER</span><span class="p">;</span>

            <span class="c1">// TO DO</span>
            <span class="c1">// receive the matrices sent from master</span>
            <span class="c1">// end TO DO</span>

            <span class="cm">/* Calling function from CUDA. Each worker computes on their GPU */</span>

            <span class="c1">// TO DO</span>
            <span class="c1">// call CUDA function</span>
            <span class="c1">// end TO DO</span>

            <span class="cm">/* Each worker sends result back to the master */</span>
            <span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_WORKER</span><span class="p">;</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span> <span class="n">rows</span><span class="o">*</span><span class="n">COL_B</span><span class="p">,</span> <span class="n">MPI_FLOAT</span><span class="p">,</span> <span class="n">MASTER</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Finally, we need to ask the master to receive the result matrix sent from each worker, and prints the result matrix.</p>
<div class="highlight-c"><div class="highlight"><pre><span class="cm">/* Receive results from worker tasks */</span>
<span class="n">mtype</span> <span class="o">=</span> <span class="n">FROM_WORKER</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">numworkers</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">source</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">offset</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">[</span><span class="n">offset</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">rows</span><span class="o">*</span><span class="n">COL_B</span><span class="p">,</span> <span class="n">MPI_FLOAT</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mtype</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Received results from task %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/* Master prints results */</span>
<span class="n">printf</span><span class="p">(</span><span class="s">&quot;******************************************************</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">&quot;Result Matrix:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ROW_A</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">COL_B</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%6.2f   &quot;</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Download the source code to do your activity:</dt>
<dd><p class="first"><a class="reference download internal" href="../_downloads/matrix_mul_todo.cu"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">CUDA</span> <span class="pre">program</span></tt></a></p>
<p class="last"><a class="reference download internal" href="../_downloads/matrix_mul_todo.c"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">MPI</span> <span class="pre">program</span></tt></a></p>
</dd>
<dt>Download the entire source code:</dt>
<dd><p class="first"><a class="reference download internal" href="../_downloads/matrix_mul.cu"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">CUDA</span> <span class="pre">program</span></tt></a></p>
<p class="last"><a class="reference download internal" href="../_downloads/matrix_mul.c"><tt class="xref download docutils literal"><span class="pre">download</span> <span class="pre">MPI</span> <span class="pre">program</span></tt></a></p>
</dd>
</dl>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Activities</a><ul>
<li><a class="reference internal" href="#activity-2-vector-matrix-multiplication">Activity 2: Vector Matrix Multiplication</a></li>
<li><a class="reference internal" href="#activity-3-matrix-multiplication">Activity 3: Matrix Multiplication</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../CodingAndCompiling/CodingAndCompiling.html"
                        title="previous chapter">Coding and Compiling a Heterogeneous Program</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../TheThreeMusketeers/TheThreeMusketeers.html"
                        title="next chapter">The Three Musketeers</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../TheThreeMusketeers/TheThreeMusketeers.html" title="The Three Musketeers"
             >next</a> |</li>
        <li class="right" >
          <a href="../CodingAndCompiling/CodingAndCompiling.html" title="Coding and Compiling a Heterogeneous Program"
             >previous</a> |</li>
        <li><a href="../index.html">Heterogeneous Computing</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>