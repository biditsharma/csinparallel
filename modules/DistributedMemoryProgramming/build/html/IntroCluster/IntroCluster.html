

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction to Cluster Computing &mdash; Distributed Computing Fundamentals</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Distributed Computing Fundamentals" href="../index.html" />
    <link rel="next" title="Local Cluster Configurations" href="../LocalClusterConfig/LocalClusterConfig.html" />
    <link rel="prev" title="Instructor/Student Notes" href="../Prerequisites/Prerequisites.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../LocalClusterConfig/LocalClusterConfig.html" title="Local Cluster Configurations"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="../Prerequisites/Prerequisites.html" title="Instructor/Student Notes"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Distributed Computing Fundamentals</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="introduction-to-cluster-computing">
<h1>Introduction to Cluster Computing<a class="headerlink" href="#introduction-to-cluster-computing" title="Permalink to this headline">¶</a></h1>
<p>This course module is focused on distributed memory computing using a cluster of computers.
This sextion is a brief overview of parallel systems and clusters, designed to get you in the frame of mind for the examples you will try on a cluster.</p>
<div class="section" id="first-two-parallel-programming-models">
<h2>First, two parallel programming models<a class="headerlink" href="#first-two-parallel-programming-models" title="Permalink to this headline">¶</a></h2>
<p>To prepare for what you will be working on, you need a basic understanding of parallel computer architectures. In particular, it is useful to know the difference between these two parallel computer architectures:</p>
<blockquote>
<div><ul class="simple">
<li>Shared Memory Model</li>
<li>Distributed Memory Model</li>
</ul>
</div></blockquote>
<p>General Characteristics of Shared Memory Model:</p>
<dl class="docutils">
<dt>&#8220;</dt>
<dd><ul class="first last simple">
<li>Shared memory parallel computers vary widely, but generally have in common the ability for all processors to access all memory as global address space.</li>
<li>Multiple processors can operate independently but share the same memory resources.</li>
<li>Changes in a memory location effected by one processor are visible to all other processors.&#8221; [2]</li>
</ul>
</dd>
</dl>
<img alt="MPI Structure" class="align-center" src="../_images/SharedMemoryUMA.png" style="width: 350px; height: 250px;" />
<p class="centered">
<strong>Figure 1: Shared Memory: Uniform Memory Access Obtained from www.computing.llnl.gov [3]</strong></p><p>The rest of this course module is primarily focused on the distributed memory model of computing, which is different from the shared memory model.</p>
<p>According to [4], the general characteristics of Distributed Memory Model are:</p>
<dl class="docutils">
<dt><strong>&#8220;</strong></dt>
<dd><ul class="first last simple">
<li>Distributed memory systems require a communication network to connect inter-processor memory.</li>
<li>Processors have their own local memory. Memory addresses in one processor do not map to another processor, so there is no concept of global address space across all processors.</li>
<li>Because each processor has its own local memory, it operates independently. Changes it makes to its local memory have no effect on the memory of other processors. Hence, the concept of cache coherency does not apply.</li>
<li>When a processor needs access to data in another processor, it is usually the task of the programmer to explicitly define how and when data is communicated. Synchronization between tasks is likewise the programmer&#8217;s responsibility.</li>
</ul>
</dd>
</dl>
<p><strong>&#8220;</strong></p>
<img alt="MPI Structure" class="align-center" src="../_images/DistributedMemory.png" style="width: 450px; height: 200px;" />
<p class="centered">
<strong>Figure 2: Distributed Memory System Obtained from www.computing.llnl.gov [5]</strong></p></div>
<div class="section" id="clusters-of-computers">
<h2>Clusters of Computers<a class="headerlink" href="#clusters-of-computers" title="Permalink to this headline">¶</a></h2>
<p>Distributed Memory systems often manifest themseleves in the form of clusters of computers networked together over a high-speed network. Clusters of workstations connected through a highspeed switch are often called beowulf clusters.</p>
<p><strong>Definition</strong>: A cluster is a type of parallel or distributed processing system, which consists of a collection of interconnected stand-alone computers cooperatively working together as a single, integrated computing resource. [1]</p>
<p>A cluster is usually a linux-based operating system. Basically, a cluster has four major components:</p>
<blockquote>
<div><ul class="simple">
<li>Network is to provide communications between nodes and server.</li>
<li>Each node has its own processor, memory, and storage.</li>
<li>Server is to provide network services to the cluster.</li>
<li>Gateway acts as a firewall between the outside world and the cluster.</li>
</ul>
</div></blockquote>
<p>Some benefits of using clusters are:</p>
<blockquote>
<div><ul class="simple">
<li>Inexpensive: Hardware and software of a cluster cost significantly much less than those of a supercomputer.</li>
<li>Scalability: extra nodes can be added to a cluster when work exceeds the capacities of the current system in the cluster.</li>
<li>Maintenance: A cluster is relatively easy to set up and maintain.</li>
<li>High Performance: Operations should be optimized and efficient.</li>
<li>Great capacity: Ability to solve a larger problem size.</li>
</ul>
</div></blockquote>
<p>There are many applications of clustering such as:</p>
<blockquote>
<div><ul class="simple">
<li>Scientific computation</li>
<li>Parametric Simulations</li>
<li>Database Applications</li>
<li>Internet Applications</li>
<li>E-commerce Applications</li>
</ul>
</div></blockquote>
<div class="topic">
<p class="topic-title first">Recommended Reading:</p>
<ul class="simple">
<li>Please read <a class="reference external" href="http://www.cloudbus.org/papers/ic_cluster.pdf">Cluster Computing: High-Performance, High-Availability, and High-Throughput Processing on a Network of Computers</a> [6].</li>
<li>Case Studies on Cluster Applications: read from page 16 - 22.</li>
</ul>
</div>
<p>In order to use a cluster effectively, we need to have some programming environments such as Message Passing Interface (MPI), and OpenMP, etc. In this module, we will be learning about MPI on distributed memory cluster.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td>Rajkumar Buyya, &#8220;High Performance Cluster Computing: Systems and Architectures&#8221;, Vol. 1, 1/e, Prentice Hall PTR, NJ, 1999.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/parallel_comp/#SharedMemory">https://computing.llnl.gov/tutorials/parallel_comp/#SharedMemory</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/parallel_comp/#SharedMemory">https://computing.llnl.gov/tutorials/parallel_comp/#SharedMemory</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[4]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/parallel_comp/#DistributedMemory">https://computing.llnl.gov/tutorials/parallel_comp/#DistributedMemory</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[5]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/parallel_comp/#DistributedMemory">https://computing.llnl.gov/tutorials/parallel_comp/#DistributedMemory</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[6]</td><td>Chee Shin Yeo, Rajkumar Buyya, Hossein Pourreza, Rasit Eskicioglu, Peter Graham, and Frank Sommers, &#8220;Cluster Computing: High-Performance, High-Availability, and High-Throughput Processing on a Network of Computers&#8221;, in Handbook of Nature-Inspired and Innovative Computing: Integrating Classical Models with Emerging Technologies, chapter 16, page 521 - 551, 2006</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction to Cluster Computing</a><ul>
<li><a class="reference internal" href="#first-two-parallel-programming-models">First, two parallel programming models</a></li>
<li><a class="reference internal" href="#clusters-of-computers">Clusters of Computers</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../Prerequisites/Prerequisites.html"
                        title="previous chapter">Instructor/Student Notes</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../LocalClusterConfig/LocalClusterConfig.html"
                        title="next chapter">Local Cluster Configurations</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../LocalClusterConfig/LocalClusterConfig.html" title="Local Cluster Configurations"
             >next</a></li>
        <li class="right" >
          <a href="../Prerequisites/Prerequisites.html" title="Instructor/Student Notes"
             >previous</a> |</li>
        <li><a href="../index.html">Distributed Computing Fundamentals</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>