
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>MPI Communications &#8212; Distributed Computing Fundamentals</title>
    
    <link rel="stylesheet" href="../_static/csip.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compiling and First Two Activites" href="../CompileAndActivity/compileandactivity.html" />
    <link rel="prev" title="Introduction to MPI" href="../introMPI/introMPI.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../CompileAndActivity/compileandactivity.html" title="Compiling and First Two Activites"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="../introMPI/introMPI.html" title="Introduction to MPI"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Distributed Computing Fundamentals</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="mpi-communications">
<h1>MPI Communications<a class="headerlink" href="#mpi-communications" title="Permalink to this headline">¶</a></h1>
<div class="section" id="point-to-point-communication">
<h2>Point-to-point Communication<a class="headerlink" href="#point-to-point-communication" title="Permalink to this headline">¶</a></h2>
<p>Point-to-point communication is a way that pair of processors transmits the data between one another, one processor sending, and the other receiving. MPI provides SEND(MPI_Send) and RECEIVE(MPI_Recv) functions that allow point-to-point communication taking place in a communicator.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">MPI_Send</span><span class="p">(</span><span class="n">void</span><span class="o">*</span> <span class="n">message</span><span class="p">,</span> <span class="nb">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="nb">int</span> <span class="n">destination</span><span class="p">,</span> <span class="nb">int</span> <span class="n">tag</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">)</span>

        <span class="o">-</span> <span class="n">message</span><span class="p">:</span>      <span class="n">initial</span> <span class="n">address</span> <span class="n">of</span> <span class="n">the</span> <span class="n">message</span>
        <span class="o">-</span> <span class="n">count</span><span class="p">:</span>        <span class="n">number</span> <span class="n">of</span> <span class="n">entries</span> <span class="n">to</span> <span class="n">send</span>
        <span class="o">-</span> <span class="n">datatype</span><span class="p">:</span>     <span class="nb">type</span> <span class="n">of</span> <span class="n">each</span> <span class="n">entry</span>
        <span class="o">-</span> <span class="n">destination</span><span class="p">:</span>  <span class="n">rank</span> <span class="n">of</span> <span class="n">the</span> <span class="n">receiving</span> <span class="n">process</span>
        <span class="o">-</span> <span class="n">tag</span><span class="p">:</span>          <span class="n">message</span> <span class="n">tag</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">way</span> <span class="n">to</span> <span class="n">identify</span> <span class="n">the</span> <span class="nb">type</span> <span class="n">of</span> <span class="n">a</span> <span class="n">message</span>
        <span class="o">-</span> <span class="n">comm</span><span class="p">:</span>         <span class="n">communicator</span> <span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">)</span>

<span class="n">MPI_Recv</span><span class="p">(</span><span class="n">void</span><span class="o">*</span> <span class="n">message</span><span class="p">,</span> <span class="nb">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="nb">int</span> <span class="n">source</span><span class="p">,</span> <span class="nb">int</span> <span class="n">tag</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_Status</span> <span class="o">*</span><span class="n">status</span><span class="p">)</span>

        <span class="o">-</span> <span class="n">source</span><span class="p">:</span>       <span class="n">rank</span> <span class="n">of</span> <span class="n">the</span> <span class="n">sending</span> <span class="n">process</span>
        <span class="o">-</span> <span class="n">status</span><span class="p">:</span>       <span class="k">return</span> <span class="n">status</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">To read more on MPI_Status, please read <a class="reference external" href="http://www.netlib.org/utk/papers/mpi-book/node31.html">MPI_Status</a>.</p>
</div>
<div class="section" id="mpi-datatype">
<h3>MPI Datatype<a class="headerlink" href="#mpi-datatype" title="Permalink to this headline">¶</a></h3>
<p>In most MPI functions, which you will be using, require you to specify the datatype of your message. Below is the table showing the corresponding datatype between MPI Datatype and C Datatype.</p>
<table border="1" class="docutils">
<colgroup>
<col width="46%" />
<col width="54%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">MPI Datatype</th>
<th class="head">C Datatype</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>MPI_CHAR</td>
<td>signed char</td>
</tr>
<tr class="row-odd"><td>MPI_SHORT</td>
<td>signed short int</td>
</tr>
<tr class="row-even"><td>MPI_INT</td>
<td>signed int</td>
</tr>
<tr class="row-odd"><td>MPI_LONG</td>
<td>signed long int</td>
</tr>
<tr class="row-even"><td>MPI_UNSIGNED_CHAR</td>
<td>unsigned char</td>
</tr>
<tr class="row-odd"><td>MPI_UNSIGNED_SHORT</td>
<td>unsigned short int</td>
</tr>
<tr class="row-even"><td>MPI_UNSIGNED</td>
<td>unsigned int</td>
</tr>
<tr class="row-odd"><td>MPI_UNSIGNED_LONG</td>
<td>unsigned long int</td>
</tr>
<tr class="row-even"><td>MPI_FLOAT</td>
<td>float</td>
</tr>
<tr class="row-odd"><td>MPI_DOUBLE</td>
<td>double</td>
</tr>
<tr class="row-even"><td>MPI_LONG_DOUBLE</td>
<td>long double</td>
</tr>
</tbody>
</table>
<p><strong>Table 1: Corresponding datatype between MPI and C</strong></p>
</div>
<div class="section" id="example-2-send-and-receive-hello-world">
<h3>Example 2: Send and Receive Hello World<a class="headerlink" href="#example-2-send-and-receive-hello-world" title="Permalink to this headline">¶</a></h3>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&quot;mpi.h&quot;</span><span class="cp"></span>

<span class="cp">#define FROM_MASTER 1</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>

    <span class="kt">int</span> <span class="n">rank</span><span class="p">,</span> <span class="n">nprocs</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">message</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;Hello, world&quot;</span><span class="p">;</span>
    
    <span class="cm">/* status for MPI_Recv */</span>
    <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>
    
    <span class="cm">/* Initialize MPI execution environment */</span>
    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="cm">/* Determines the size of MPI_COMM_WORLD */</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">nprocs</span><span class="p">)</span>
    <span class="cm">/* Give each process a unique rank */</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>
	
    <span class="cm">/* If the process is the master */</span>
    <span class="k">if</span> <span class="p">(</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span>
        <span class="cm">/* Send message to process whose rank is 1 in the MPI_COMM_WORLD */</span>
        <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">FROM_MASTER</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="cm">/* If the process has rank of 1 */</span>
    <span class="k">else</span> <span class="k">if</span> <span class="p">(</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">)</span> <span class="p">{</span>
        <span class="cm">/* Receive message sent from master */</span>
        <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">FROM_MASTER</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="cm">/* Print the rank and message */</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d says : %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">message</span><span class="p">);</span> 
    <span class="p">}</span>
    
    <span class="cm">/* Terminate MPI execution environment */</span>
    <span class="n">MPI_Finalize</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Comments:</th><td class="field-body">This MPI program illustrates the use of MPI_Send and MPI_Recv functions. Basically, the master sends a message, “Hello, world”, to the process whose rank is 1, and then after having received the message, the process prints the message along with its rank.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="collective-communication">
<h2>Collective Communication<a class="headerlink" href="#collective-communication" title="Permalink to this headline">¶</a></h2>
<p>Collective communication is a communication that must have all processes involved in the scope of a communicator. We will be using MPI_COMM_WORLD as our communicator; therefore, the collective communication will include all processes.</p>
<a class="reference internal image-reference" href="../_images/collective.png"><img alt="MPI_COMM_WORLD" class="align-center" src="../_images/collective.png" style="width: 450px; height: 350px;" /></a>
<p class="centered">
<strong>Figure 5: Collective Communications Obtained from computing.llnl.gov [1]</strong></p><div class="highlight-c"><div class="highlight"><pre><span></span><span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">comm</span><span class="p">)</span>
</pre></div>
</div>
<p>This function creates a barrier synchronization in a commmunicator(MPI_COMM_WORLD). Each task waits at MPI_Barrier call until all other tasks in the communicator reach the same MPI_Barrier call.</p>
<div class="highlight-c"><div class="highlight"><pre><span></span><span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">comm</span><span class="p">)</span>
</pre></div>
</div>
<p>This function displays the message to all other processes in MPI_COMM_WORLD from the process whose rank is root.</p>
<div class="highlight-c"><div class="highlight"><pre><span></span><span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">receivemessage</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">MPI_Op</span> <span class="n">op</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">comm</span><span class="p">)</span>
</pre></div>
</div>
<p>This function applies a reduction operation on all tasks in MPI_COMM_WORLD and reduces results from each process into one value. MPI_Op includes for example, MPI_MAX, MPI_MIN, MPI_PROD, and MPI_SUM, etc.</p>
<blockquote>
<div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">To read more on MPI_Op, please read <a class="reference external" href="http://www.mpi-forum.org/docs/mpi-11-html/node78.html#Node78">MPI_Op</a>.</p>
</div>
</div></blockquote>
<div class="highlight-c"><div class="highlight"><pre><span></span><span class="n">MPI_Scatter</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">receivemessage</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">comm</span><span class="p">)</span>
</pre></div>
</div>
<p>This function divides a message into equal contiguous parts and sends each part to each node. The master gets the first part, and the process whose rank is 1 gets the second part, and so on. The number of elements get sent to each worker is specified by count.</p>
<div class="highlight-c"><div class="highlight"><pre><span></span><span class="n">MPI_Gather</span><span class="p">(</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">receivemessage</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">comm</span><span class="p">)</span>
</pre></div>
</div>
<p>This function collects distinct messages from each task in the communicator to a single task. This function is the reverse operation of MPI_Scatter.</p>
</div>
<div class="section" id="let-s-try-it">
<h2>Let’s Try It<a class="headerlink" href="#let-s-try-it" title="Permalink to this headline">¶</a></h2>
<p>In the next section we will describe how to compile and run these examples so that you can try them.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/mpi/">https://computing.llnl.gov/tutorials/mpi/</a></td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">MPI Communications</a><ul>
<li><a class="reference internal" href="#point-to-point-communication">Point-to-point Communication</a><ul>
<li><a class="reference internal" href="#mpi-datatype">MPI Datatype</a></li>
<li><a class="reference internal" href="#example-2-send-and-receive-hello-world">Example 2: Send and Receive Hello World</a></li>
</ul>
</li>
<li><a class="reference internal" href="#collective-communication">Collective Communication</a></li>
<li><a class="reference internal" href="#let-s-try-it">Let’s Try It</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../introMPI/introMPI.html"
                        title="previous chapter">Introduction to MPI</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../CompileAndActivity/compileandactivity.html"
                        title="next chapter">Compiling and First Two Activites</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../CompileAndActivity/compileandactivity.html" title="Compiling and First Two Activites"
             >next</a></li>
        <li class="right" >
          <a href="../introMPI/introMPI.html" title="Introduction to MPI"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Distributed Computing Fundamentals</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.2.
    </div>
  </body>
</html>