
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction to MPI &#8212; Distributed Computing Fundamentals</title>
    
    <link rel="stylesheet" href="../_static/csip.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MPI Communications" href="../MPICommunication/MPICommunication.html" />
    <link rel="prev" title="Local Cluster Configurations" href="../LocalClusterConfig/LocalClusterConfig.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../MPICommunication/MPICommunication.html" title="MPI Communications"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="../LocalClusterConfig/LocalClusterConfig.html" title="Local Cluster Configurations"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Distributed Computing Fundamentals</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="introduction-to-mpi">
<h1>Introduction to MPI<a class="headerlink" href="#introduction-to-mpi" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-mpi">
<h2>What is MPI ?<a class="headerlink" href="#what-is-mpi" title="Permalink to this headline">¶</a></h2>
<p>Message Passing Interface (MPI) is a subroutine or a library for passing messages between processes in a distributed memory model. MPI is not a programming language. MPI is a programming model that is widely used for parallel programming in a cluster. In the cluster, the head node is known as the master, and the other nodes are known as the workers. By using MPI, programmers are able to divide up the task and distribute each task to each worker or to some specific workers. Thus, each node can work on its own task simultaneously.</p>
<p>Since this is a small module, we will be focusing on only important and common MPI functions and techniques. For further study, there are a lot of free resources available on the Internet.</p>
</div>
<div class="section" id="why-mpi">
<h2>Why MPI ?<a class="headerlink" href="#why-mpi" title="Permalink to this headline">¶</a></h2>
<p>There are many reasons for using MPI as our parallel programming model:</p>
<blockquote>
<div><ul class="simple">
<li>MPI is a standard message passing library, and it is supported on all high-performance computer platforms.</li>
<li>An MPI program is able to run on different platforms that support the MPI standard without changing your source codes.</li>
<li>Because of its parallel features, programmers are able to work on a much larger problem size with the faster computation.</li>
<li>There are many useful functions available in the MPI Library.</li>
<li>A variety of implementations are available.</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="how-do-i-write-an-mpi-program">
<h2>How do I write an MPI program ?<a class="headerlink" href="#how-do-i-write-an-mpi-program" title="Permalink to this headline">¶</a></h2>
<p>In order to get the MPI library working, you need to include the header file <strong>#include &lt;mpi.h&gt;</strong> or <strong>#include “mpi.h”</strong> in your C code.</p>
<div class="section" id="mpi-program-structure">
<h3>MPI Program Structure<a class="headerlink" href="#mpi-program-structure" title="Permalink to this headline">¶</a></h3>
<p>Like other programming languages you have seen, program that includes MPI library has its structure. The structure is shown in the figure below:</p>
<a class="reference internal image-reference" href="../_images/MPIstructure.png"><img alt="MPI Structure" class="align-center" src="../_images/MPIstructure.png" style="width: 550px; height: 400px;" /></a>
<p class="centered">
<strong>Figure 3: MPI program structure Obtained from computing.llnl.gov [1]</strong></p><p>A MPI program is basically a C program that uses the MPI library, SO DON’T BE SCARED. The program has two different parts, one is serial, and the other is parallel. The serial part contains variable declarations, etc., and the parallel part starts when MPI execution environment has been initialized, and ends when MPI_Finalize() has been called.</p>
<p><strong>Communicator</strong>: a set of processes that have a valid rank of source or destination fields. The predefined communicator is MPI_COMM_WORLD, and we will be using this communicator all the time in this module. MPI_COMM_WORLD is a default communicator consisting all processes. Furthermore, a programmer can also define a new communicator, which has a smaller number of processes than MPI_COMM_WORLD does.</p>
<a class="reference internal image-reference" href="../_images/MPI_COMM_WORLD.png"><img alt="MPI_COMM_WORLD" class="align-center" src="../_images/MPI_COMM_WORLD.png" style="width: 400px; height: 250px;" /></a>
<p class="centered">
<strong>Figure 4: MPI_COMM_WORLD Obtained from computing.llnl.gov [2]</strong></p><p><strong>Processes</strong>: For this module, we just need to know that processes belong to the MPI_COMM_WORLD. If there are <em>p</em> processes, then each process is defined by its rank, which starts from <em>0</em> to <em>p - 1</em>. The master has the rank <em>0</em>.</p>
</div>
<div class="section" id="some-common-functions">
<h3>Some Common Functions:<a class="headerlink" href="#some-common-functions" title="Permalink to this headline">¶</a></h3>
<p>The following functions are the functions that are commonly used in MPI programs:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">)</span>
</pre></div>
</div>
<p>This function has to be called in every MPI program. It is used to initialize the MPI execution environment.</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size</span><span class="p">)</span>
</pre></div>
</div>
<p>This function determines the number of processes in the communicator. The number of processes get store in the variable <em>size</em>. All processes in a communicator have the same value of <em>size</em>.</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">)</span>
</pre></div>
</div>
<p>This function determines the rank of the calling process within the communicator. Each process is assigned uniquely by integer rank from <em>0</em> to <em>number of processes - 1</em>, and its rank gets stored in the variable <em>rank</em>.</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="nb">len</span><span class="p">)</span>
</pre></div>
</div>
<p>This function returns the unique processor name. Variable <em>name</em> is the array of char for storing the name, and <em>len</em> is the length of the name.</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Wtime</span><span class="p">()</span>
</pre></div>
</div>
<p>This function returns an elapsed wall clock time in seconds on the calling processor. This function is often used to measure the running time of an MPI program. There is no defined starting point; therefore, in order to measure the running time, a programmer needs to call two different MPI_Wtime(), and find the difference.</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">MPI_Finalize</span><span class="p">()</span>
</pre></div>
</div>
<p>This function terminates the MPI execution environment. MPI_Finalize() has to be called by all processes before exiting.</p>
<div class="section" id="example-1-hello-world-mpi">
<h4>Example 1: Hello World MPI<a class="headerlink" href="#example-1-hello-world-mpi" title="Permalink to this headline">¶</a></h4>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="highlight"><pre><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span> <span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
	<span class="kt">int</span> <span class="n">rank</span><span class="p">,</span> <span class="n">nprocs</span><span class="p">;</span>

	<span class="n">MPI_Init</span> <span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>	<span class="cm">/* creates MPI execution environment */</span>
	<span class="n">MPI_Comm_rank</span> <span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>	<span class="cm">/* get current process rank */</span>
	<span class="n">MPI_Comm_size</span> <span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">nprocs</span><span class="p">);</span><span class="cm">/* get number of processes */</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello world from process %d of %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">nprocs</span><span class="p">);</span>
	<span class="n">MPI_Finalize</span><span class="p">();</span>			<span class="cm">/* terminates the MPI execution environment */</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Comments:</th><td class="field-body">In this hello world program, it illustrates how to use some basic functions of MPI. First, it initializes the MPI execution environment. Then it prints “Hello world from process [rank] of [number of processes]”. Finally, it terminates the MPI execution environment.</td>
</tr>
</tbody>
</table>
<p>You should eventually try to compile and run this code on your cluster account. Before that, we will explain a bit more about communication between processes, showing you another ‘Hello World’ Example.  Then we will show you how to compile and run these programs.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/mpi/">https://computing.llnl.gov/tutorials/mpi/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><a class="reference external" href="https://computing.llnl.gov/tutorials/mpi/">https://computing.llnl.gov/tutorials/mpi/</a></td></tr>
</tbody>
</table>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction to MPI</a><ul>
<li><a class="reference internal" href="#what-is-mpi">What is MPI ?</a></li>
<li><a class="reference internal" href="#why-mpi">Why MPI ?</a></li>
<li><a class="reference internal" href="#how-do-i-write-an-mpi-program">How do I write an MPI program ?</a><ul>
<li><a class="reference internal" href="#mpi-program-structure">MPI Program Structure</a></li>
<li><a class="reference internal" href="#some-common-functions">Some Common Functions:</a><ul>
<li><a class="reference internal" href="#example-1-hello-world-mpi">Example 1: Hello World MPI</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../LocalClusterConfig/LocalClusterConfig.html"
                        title="previous chapter">Local Cluster Configurations</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../MPICommunication/MPICommunication.html"
                        title="next chapter">MPI Communications</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../MPICommunication/MPICommunication.html" title="MPI Communications"
             >next</a></li>
        <li class="right" >
          <a href="../LocalClusterConfig/LocalClusterConfig.html" title="Local Cluster Configurations"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Distributed Computing Fundamentals</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.2.
    </div>
  </body>
</html>