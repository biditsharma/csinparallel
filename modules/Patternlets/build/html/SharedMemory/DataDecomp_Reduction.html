
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Data Decomposition Algorithm Strategies and Related Coordination Strategies &#8212; Parallel Patternlets</title>
    <link rel="stylesheet" href="../_static/csip.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Patterns used when threads share data values" href="MutualExclusion.html" />
    <link rel="prev" title="Shared Memory Program Structure and Coordination Patterns" href="ProgStructure_Barrier.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="MutualExclusion.html" title="Patterns used when threads share data values"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="ProgStructure_Barrier.html" title="Shared Memory Program Structure and Coordination Patterns"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="OpenMP_Patternlets.html" accesskey="U">Shared Memory Parallel Patternlets in OpenMP</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="data-decomposition-algorithm-strategies-and-related-coordination-strategies">
<h1>Data Decomposition Algorithm Strategies and Related Coordination Strategies<a class="headerlink" href="#data-decomposition-algorithm-strategies-and-related-coordination-strategies" title="Permalink to this headline">¶</a></h1>
<div class="section" id="shared-data-decomposition-algorithm-strategy-chunks-of-data-per-thread-using-a-parallel-for-loop-implementation-strategy">
<h2>6. Shared Data Decomposition Algorithm Strategy:  chunks of data per thread using a parallel for loop implementation strategy<a class="headerlink" href="#shared-data-decomposition-algorithm-strategy-chunks-of-data-per-thread-using-a-parallel-for-loop-implementation-strategy" title="Permalink to this headline">¶</a></h2>
<p><em>file: openMP/06.parallelLoop-equalChunks/parallelLoopEqualChunks.c</em></p>
<p><em>Build inside 06.parallelLoop-equalChunks directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">parallelLoopEqualChunks</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 06.parallelLoop-equalChunks directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">parallelLoopEqualChunks</span> <span class="mi">4</span>
<span class="n">Replace</span> <span class="mi">4</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span><span class="p">,</span> <span class="ow">or</span> <span class="n">leave</span> <span class="n">off</span>
</pre></div>
</div>
<p>An iterative for loop is a remarkably common pattern in all programming, primarily used to
perform a calculation N times, often over a set of data containing N elements, using each
element in turn inside the for loop.  If there are no dependencies between the calculations
(i.e. the order of them is not important), then the code inside the loop can be split
between forked threads.  When doing this, a decision the programmer needs to make is to
decide how to partition the work between the threads by answering this question:</p>
<ul class="simple">
<li>How many and which iterations of the loop will each thread complete on its own?</li>
</ul>
<p>We refer to this as the <strong>data decomposition</strong> pattern because we are decomposing the
amount of work to be done (typically on a set of data) across multiple threads.
In the following code, this is done in OpenMP using the <em>omp parallel for</em> pragma
just in front of the for statement (line 27) in the following code.</p>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* parallelLoopEqualChunks.c</span>
<span class="cm"> * ... illustrates the use of OpenMP&#39;s default parallel for loop in which</span>
<span class="cm"> *  	threads iterate through equal sized chunks of the index range</span>
<span class="cm"> *	(cache-beneficial when accessing adjacent memory locations).</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: ./parallelLoopEqualChunks [numThreads]</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise</span>
<span class="cm"> * - Compile and run, comparing output to source code</span>
<span class="cm"> * - try with different numbers of threads, e.g.: 2, 3, 4, 6, 8</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;    // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;   // atoi()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;      // OpenMP</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">REPS</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">omp_set_num_threads</span><span class="p">(</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">);</span>
    <span class="p">}</span>

    <span class="cp">#pragma omp parallel for  </span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">REPS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Thread %d performed iteration %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> 
                 <span class="n">id</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
<p>Once you run this code, verify that the default behavior for this pragma is this
sort of decomposition of iterations of the loop to threads, when you set the
number of threads to 4 on the command line:</p>
<img alt="../_images/ParalleFor_Chunks-4_threads-1.png" src="../_images/ParalleFor_Chunks-4_threads-1.png" />
<p>What happens when the number of iterations (16 in this code) is not evenly divisible by the number of threads?  Try several cases to be certain how the compiler splits up the work.
This type of decomposition is commonly used when accessing data that is stored in
consecutive memory locations (such as an array) that might be cached by each thread.</p>
</div>
<div class="section" id="shared-data-decomposition-algorithm-strategy-one-iteration-per-thread-in-a-parallel-for-loop-implementation-strategy">
<h2>7. Shared Data Decomposition Algorithm Strategy:  one iteration per thread in a parallel for loop implementation strategy<a class="headerlink" href="#shared-data-decomposition-algorithm-strategy-one-iteration-per-thread-in-a-parallel-for-loop-implementation-strategy" title="Permalink to this headline">¶</a></h2>
<p><em>file: openMP/07.parallelLoop-chunksOf1/parallelLoopChunksOf1.c</em></p>
<p><em>Build inside 07.parallelLoop-chunksOf1 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">parallelLoopChunksOf1</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 07.parallelLoop-chunksOf1 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">parallelLoopChunksOf1</span> <span class="mi">4</span>
<span class="n">Replace</span> <span class="mi">4</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span><span class="p">,</span> <span class="ow">or</span> <span class="n">leave</span> <span class="n">off</span>
</pre></div>
</div>
<p>You can imagine other ways of assigning threads to iterations of a loop besides that
shown above for four threads and 16 iterations.  A simple decomposition sometimes used
when your loop is not accessing consecutive memory locations would be to let each
thread do one iteration, up to N threads, then
start again with thread 0 taking the next iteration.  This is declared in OpenMP
using the pragma on line 31 of the following code.  Also note that the commented code
below it is an alternative explicit way of doing it.  The schedule clause is the preferred style
when using OpenMP and is more versatile, because you can easily change the <cite>chunk size</cite>
that each thread will work on.</p>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* parallelLoopChunksOf1.c</span>
<span class="cm"> * ... illustrates how to make OpenMP map threads to </span>
<span class="cm"> *	parallel loop iterations in chunks of size 1</span>
<span class="cm"> *	(use when not accesssing memory).</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: ./parallelLoopChunksOf1 [numThreads]</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * 1. Compile and run, comparing output to source code,</span>
<span class="cm"> *    and to the output of the &#39;equal chunks&#39; version.</span>
<span class="cm"> * 2. Uncomment the &quot;commented out&quot; code below,</span>
<span class="cm"> *    and verify that both loops produce the same output.</span>
<span class="cm"> *    The first loop is simpler but more restrictive;</span>
<span class="cm"> *    the second loop is more complex but less restrictive.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">REPS</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">omp_set_num_threads</span><span class="p">(</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">);</span>
    <span class="p">}</span>

    <span class="cp">#pragma omp parallel for schedule(static,1)</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">REPS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Thread %d performed iteration %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> 
                 <span class="n">id</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
    <span class="p">}</span>

<span class="cm">/*</span>
<span class="cm">    printf(&quot;\n---\n\n&quot;);</span>

<span class="cm">    #pragma omp parallel</span>
<span class="cm">    {</span>
<span class="cm">        int id = omp_get_thread_num();</span>
<span class="cm">        int numThreads = omp_get_num_threads();</span>
<span class="cm">        for (int i = id; i &lt; REPS; i += numThreads) {</span>
<span class="cm">            printf(&quot;Thread %d performed iteration %d\n&quot;, </span>
<span class="cm">                     id, i);</span>
<span class="cm">        }</span>
<span class="cm">    }</span>
<span class="cm">*/</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
<p>This can be made even more
efficient if the next available thread simply takes the next iteration.
In OpenMP, this is done by using <em>dynamic</em> scheduling instead of the static scheduling shown
in the above code.  Also note that the number of iterations, or chunk size, could
be greater than 1 inside the schedule clause.</p>
</div>
<div class="section" id="coordination-using-collective-communication-reduction">
<h2>8. Coordination Using Collective Communication: Reduction<a class="headerlink" href="#coordination-using-collective-communication-reduction" title="Permalink to this headline">¶</a></h2>
<p><em>file: openMP/08.reduction/reduction.c</em></p>
<p><em>Build inside 08.reduction directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">reduction</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 08.reduction directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">reduction</span> <span class="mi">4</span>
<span class="n">Replace</span> <span class="mi">4</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span><span class="p">,</span> <span class="ow">or</span> <span class="n">leave</span> <span class="n">off</span>
</pre></div>
</div>
<p>Once threads have performed independent concurrent computations, possibly
on some portion of decomposed data, it is quite common to then <em>reduce</em>
those individual computations into one value. This type of operation is
called a <strong>collective communication</strong> pattern because the threads must somehow
work together to create the final desired single value.</p>
<p>In this example, an array of randomly assigned integers represents a set of shared data (a more realistic program would perform a computation
that creates meaningful data values; this is just an example).
Note the common sequential code pattern found in the function called <em>sequentialSum</em> in the code
below (starting line 51): a for loop is used to sum up all the values in the array.</p>
<p>Next let’s consider how this can be done in parallel with threads.
Somehow the threads must implicitly <cite>communicate</cite> to keep the overall sum updated
as each of them works on a portion of the array.
In the <em>parallelSum</em> function, line 64 shows a special clause that
can be used with the parallel for pragma in OpenMP for this. All values
in the array are summed together by using the OpenMP
parallel for pragma with the <cite>reduction(+:sum)</cite> clause on the variable <strong>sum</strong>,
which is computed in line 66.</p>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* reduction.c</span>
<span class="cm"> * ... illustrates the OpenMP parallel-for loop&#39;s reduction clause</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: ./reduction </span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run.  Note that correct output is produced.</span>
<span class="cm"> * - Uncomment #pragma in function parallelSum(), </span>
<span class="cm"> *    but leave its reduction clause commented out</span>
<span class="cm"> * - Recompile and rerun.  Note that correct output is NOT produced.</span>
<span class="cm"> * - Uncomment &#39;reduction(+:sum)&#39; clause of #pragma in parallelSum()</span>
<span class="cm"> * - Recompile and rerun.  Note that correct output is produced again.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;   // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;     // OpenMP</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;  // rand()</span><span class="cp"></span>

<span class="kt">void</span> <span class="nf">initialize</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">);</span>
<span class="kt">int</span> <span class="nf">sequentialSum</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">);</span>
<span class="kt">int</span> <span class="nf">parallelSum</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">);</span>

<span class="cp">#define SIZE 1000000</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">array</span><span class="p">[</span><span class="n">SIZE</span><span class="p">];</span>

   <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">omp_set_num_threads</span><span class="p">(</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">);</span>
   <span class="p">}</span>

   <span class="n">initialize</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">);</span>
   <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Seq. sum: </span><span class="se">\t</span><span class="s">%d</span><span class="se">\n</span><span class="s">Par. sum: </span><span class="se">\t</span><span class="s">%d</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span>
            <span class="n">sequentialSum</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">),</span>
            <span class="n">parallelSum</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">)</span> <span class="p">);</span>

   <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span> 

<span class="cm">/* fill array with random values */</span>
<span class="kt">void</span> <span class="nf">initialize</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">1000</span><span class="p">;</span>
   <span class="p">}</span>
<span class="p">}</span>

<span class="cm">/* sum the array sequentially */</span>
<span class="kt">int</span> <span class="nf">sequentialSum</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
   <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
   <span class="p">}</span>
   <span class="k">return</span> <span class="n">sum</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* sum the array using multiple threads */</span>
<span class="kt">int</span> <span class="nf">parallelSum</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
   <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
<span class="c1">//   #pragma omp parallel for // reduction(+:sum)</span>
   <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
   <span class="p">}</span>
   <span class="k">return</span> <span class="n">sum</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
<div class="section" id="something-to-think-about">
<h3>Something to think about<a class="headerlink" href="#something-to-think-about" title="Permalink to this headline">¶</a></h3>
<p>Do you have an ideas about why the parallel for pragma without the reduction clause did not
produce the correct result?  Later examples will hopefully shed some light on this.</p>
</div>
</div>
<div class="section" id="coordination-using-collective-communication-reduction-revisited">
<h2>9. Coordination Using Collective Communication: Reduction revisited<a class="headerlink" href="#coordination-using-collective-communication-reduction-revisited" title="Permalink to this headline">¶</a></h2>
<p><em>Build inside 09.reduction-userDefined directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">reduction2</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 09.reduction-userDefined directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">reduction</span>  <span class="mi">4</span> <span class="mi">4096</span>
<span class="n">Replace</span> <span class="mi">4</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span>
<span class="n">Replace</span> <span class="mi">4096</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">n</span> <span class="p">(</span><span class="n">computing</span> <span class="n">up</span> <span class="n">to</span> <span class="n">n</span> <span class="n">factorial</span><span class="p">)</span>
</pre></div>
</div>
<p>The next example uses many threads to generate computations of factorials of n. Though there are likely other better ways to compute factorials, this
example uses a very simple approach to illustrate how reduction can be used with the
multiplication operation instead of addition in the previous example. The pragma for
this is on line 34 in the code below, which also makes use of an additional C++ file, BigInt.h:</p>
<div class="highlight-c++"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* reduction2.cpp computes a table of factorial values,</span>
<span class="cm"> *  using Owen Astrachan&#39;s BigInt class to explore</span>
<span class="cm"> *  OpenMP&#39;s user-defined reductions.</span>
<span class="cm"> *</span>
<span class="cm"> *  Joel Adams, Calvin College, December 2015.</span>
<span class="cm"> *</span>
<span class="cm"> *  Usage: ./reduction2 [numThreads] [n]</span>
<span class="cm"> *</span>
<span class="cm"> *  Exercise:</span>
<span class="cm"> *  - Build and run, record sequential time in a spreadsheet</span>
<span class="cm"> *  - Uncomment #pragma omp parallel for directive, rebuild,</span>
<span class="cm"> *     and read the error message carefully.</span>
<span class="cm"> *  - Uncomment the #pragma omp declare directive, rebuild,</span>
<span class="cm"> *     and note the user-defined * reduction for a BigInt.</span>
<span class="cm"> *  - Rerun, using 2, 4, 6, 8, ... threads, recording</span>
<span class="cm"> *     the times in the spreadsheet.</span>
<span class="cm"> *  - Create a chart that plots the times vs the # of threads.</span>
<span class="cm"> *  - Experiment with different n values</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&quot;BigInt.h&quot;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cassert&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm">#pragma omp declare reduction(*: BigInt: \</span>
<span class="cm">				omp_out = omp_out * omp_in) \</span>
<span class="cm">				initializer( omp_priv=BigInt(1))</span>
<span class="cm">*/</span>

<span class="n">BigInt</span> <span class="nf">factorial</span><span class="p">(</span><span class="kt">unsigned</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">BigInt</span> <span class="n">result</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="c1">//	#pragma omp parallel for reduction(*:result) </span>
	<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">result</span> <span class="o">*=</span> <span class="n">i</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// on a 2GHz i7 CPU:</span>
	<span class="kt">unsigned</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">;</span>         <span class="c1">// ~10 secs sequentially</span>
	<span class="kt">unsigned</span> <span class="n">numThreads</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="k">switch</span> <span class="p">(</span><span class="n">argc</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">case</span> <span class="mi">3</span><span class="o">:</span> <span class="n">n</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
		<span class="k">case</span> <span class="mi">2</span><span class="o">:</span> <span class="n">numThreads</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
		<span class="k">case</span> <span class="mi">1</span><span class="o">:</span> <span class="k">break</span><span class="p">;</span>
		<span class="k">default</span><span class="o">:</span> <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">Usage: ./reduction2 [numThreads] [n]</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">;</span>
	<span class="p">}</span>
        <span class="n">omp_set_num_threads</span><span class="p">(</span><span class="n">numThreads</span><span class="p">);</span>

	<span class="kt">double</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">omp_get_wtime</span><span class="p">();</span>
	<span class="n">BigInt</span> <span class="n">nFactorial</span> <span class="o">=</span> <span class="n">factorial</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
	<span class="kt">double</span> <span class="n">time</span> <span class="o">=</span> <span class="n">omp_get_wtime</span><span class="p">()</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">;</span>

	<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Computing &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">n</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;! using &quot;</span>
             <span class="o">&lt;&lt;</span> <span class="n">numThreads</span>  <span class="o">&lt;&lt;</span> <span class="s">&quot; threads took: &quot;</span> 
             <span class="o">&lt;&lt;</span> <span class="n">time</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; secs&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

	<span class="c1">// run a few tests to validate the results</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">==</span> <span class="mi">24</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">==</span> <span class="mi">120</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span> <span class="o">==</span> <span class="n">BigInt</span><span class="p">(</span><span class="s">&quot;263130836933693530167218012160000000&quot;</span><span class="p">)</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorial</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="n">BigInt</span><span class="p">(</span> <span class="n">string</span><span class="p">(</span><span class="s">&quot;9332621544394415268169923885&quot;</span><span class="p">)</span>
			                            <span class="o">+</span> <span class="s">&quot;6266700490715968264381621468&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;5929638952175999932299156089&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;4146397615651828625369792082&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;7223758251185210916864000000&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;000000000000000000&quot;</span> <span class="p">)</span> <span class="p">);</span>
	<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;All tests passed!</span><span class="se">\n</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">flush</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>With this code you can begin to explore the time it takes to execute the program when using increasing numbers of threads for various values of n. Follow the instructions at the top of the file.</p>
</div>
<div class="section" id="dynamic-data-decomposition">
<h2>10. Dynamic Data Decomposition<a class="headerlink" href="#dynamic-data-decomposition" title="Permalink to this headline">¶</a></h2>
<p><em>Build inside 10.parallelLoop-dynamicSchedule directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">dynamicScheduling</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 10.parallelLoop-dynamicSchedule directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">dynamicScheduling</span> <span class="mi">4</span>
<span class="n">Replace</span> <span class="mi">4</span> <span class="k">with</span> <span class="n">other</span> <span class="n">values</span> <span class="k">for</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span>
</pre></div>
</div>
<p>The following example computes factorials for the numbers 2 through 512, placing the result in an array. This array of results is the data in this data decomposition pattern. Since each number will take a different amount of time to compute, this is
a case where using dynamic scheduling of the work improves the performance. Try the tasks lsited in the header of the code shown below to see this.</p>
<div class="highlight-c++"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* dynamicScheduling.cpp computes a table of factorial values,</span>
<span class="cm"> *  using Owen Astrachan&#39;s BigInt class to explore</span>
<span class="cm"> *  OpenMP&#39;s schedule() clause.</span>
<span class="cm"> *</span>
<span class="cm"> *  @author: Joel Adams, Calvin College, Dec 2015.</span>
<span class="cm"> *</span>
<span class="cm"> *  Usage: ./dynamicScheduling [numThreads]</span>
<span class="cm"> *</span>
<span class="cm"> *  Exercise:</span>
<span class="cm"> *  - Build and run, record sequential run time in a spreadsheet</span>
<span class="cm"> *  - Uncomment #pragma omp parallel for, rebuild,</span>
<span class="cm"> *      run using 2, 4, 6, 8, ... threads, record run times.</span>
<span class="cm"> *  - Uncomment schedule(dynamic), rebuild,</span>
<span class="cm"> *      run using 2, 4, 6, 8, ... threads, record run times.</span>
<span class="cm"> *  - Create a line chart plotting run times vs # of threads.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&quot;BigInt.h&quot;                 // class BigInt</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;                    // OpenMP functions</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cassert&gt;                  // assert()</span><span class="cp"></span>

<span class="cm">/* factorial(n) computes n!</span>
<span class="cm"> * @param: n, an unsigned int.</span>
<span class="cm"> * @return: n!, a BigInt.</span>
<span class="cm"> */</span>
<span class="n">BigInt</span> <span class="nf">factorial</span><span class="p">(</span><span class="kt">unsigned</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">BigInt</span> <span class="n">result</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>              <span class="c1">// 0! or 1!</span>

	<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">result</span> <span class="o">*=</span> <span class="n">i</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>            <span class="c1">// on a 2 GHz i7 CPU:</span>
	<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">MAX</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>            <span class="c1">//  ~14 secs sequentially</span>
<span class="c1">//	const unsigned MAX = 800;            //  ~60 secs sequentially</span>
	<span class="n">BigInt</span> <span class="n">factorialTable</span><span class="p">[</span><span class="n">MAX</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span> <span class="n">omp_set_num_threads</span><span class="p">(</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">);</span> <span class="p">}</span>

	<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">Depending on the speed of your computer,&quot;</span>
             <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">  this program may take a while to complete,&quot;</span>
             <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">  so please wait patiently...</span><span class="se">\n</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

	<span class="kt">double</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">omp_get_wtime</span><span class="p">();</span>
<span class="c1">//	#pragma omp parallel for // schedule(dynamic)</span>
	<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">MAX</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">factorialTable</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">factorial</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="kt">double</span> <span class="n">totalTime</span> <span class="o">=</span> <span class="n">omp_get_wtime</span><span class="p">()</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">;</span>

	<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Computing 0! .. &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">MAX</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;! took: &quot;</span> 
             <span class="o">&lt;&lt;</span> <span class="n">totalTime</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; secs</span><span class="se">\n</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

	<span class="c1">// run a few tests to validate the results</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">6</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">==</span> <span class="mi">24</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">==</span> <span class="mi">120</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">32</span><span class="p">]</span> <span class="o">==</span> <span class="n">BigInt</span><span class="p">(</span><span class="s">&quot;263130836933693530167218012160000000&quot;</span><span class="p">)</span> <span class="p">);</span>
	<span class="n">assert</span><span class="p">(</span> <span class="n">factorialTable</span><span class="p">[</span><span class="mi">100</span><span class="p">]</span> <span class="o">==</span> <span class="n">BigInt</span><span class="p">(</span> <span class="n">string</span><span class="p">(</span><span class="s">&quot;9332621544394415268169923885&quot;</span><span class="p">)</span>
			                            <span class="o">+</span> <span class="s">&quot;6266700490715968264381621468&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;5929638952175999932299156089&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;4146397615651828625369792082&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;7223758251185210916864000000&quot;</span>
						    <span class="o">+</span> <span class="s">&quot;000000000000000000&quot;</span> <span class="p">)</span> <span class="p">);</span>
	<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;All tests passed!</span><span class="se">\n</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Data Decomposition Algorithm Strategies and Related Coordination Strategies</a><ul>
<li><a class="reference internal" href="#shared-data-decomposition-algorithm-strategy-chunks-of-data-per-thread-using-a-parallel-for-loop-implementation-strategy">6. Shared Data Decomposition Algorithm Strategy:  chunks of data per thread using a parallel for loop implementation strategy</a></li>
<li><a class="reference internal" href="#shared-data-decomposition-algorithm-strategy-one-iteration-per-thread-in-a-parallel-for-loop-implementation-strategy">7. Shared Data Decomposition Algorithm Strategy:  one iteration per thread in a parallel for loop implementation strategy</a></li>
<li><a class="reference internal" href="#coordination-using-collective-communication-reduction">8. Coordination Using Collective Communication: Reduction</a><ul>
<li><a class="reference internal" href="#something-to-think-about">Something to think about</a></li>
</ul>
</li>
<li><a class="reference internal" href="#coordination-using-collective-communication-reduction-revisited">9. Coordination Using Collective Communication: Reduction revisited</a></li>
<li><a class="reference internal" href="#dynamic-data-decomposition">10. Dynamic Data Decomposition</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="ProgStructure_Barrier.html"
                        title="previous chapter">Shared Memory Program Structure and Coordination Patterns</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="MutualExclusion.html"
                        title="next chapter">Patterns used when threads share data values</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="MutualExclusion.html" title="Patterns used when threads share data values"
             >next</a></li>
        <li class="right" >
          <a href="ProgStructure_Barrier.html" title="Shared Memory Program Structure and Coordination Patterns"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="OpenMP_Patternlets.html" >Shared Memory Parallel Patternlets in OpenMP</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>