

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Parallel Programming Patterns &mdash; Parallel Patternlets</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Parallel Patternlets" href="index.html" />
    <link rel="next" title="Message Passing Parallel Patternlets" href="MessagePassing/MPI_Patternlets.html" />
    <link rel="prev" title="Parallel Patternlets" href="index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="MessagePassing/MPI_Patternlets.html" title="Message Passing Parallel Patternlets"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="index.html" title="Parallel Patternlets"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Parallel Patternlets</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="parallel-programming-patterns">
<h1>Parallel Programming Patterns<a class="headerlink" href="#parallel-programming-patterns" title="Permalink to this headline">¶</a></h1>
<p>Like all programs, parallel programs contain many <strong>patterns</strong>: useful ways of writing code that are used repeatedly by most developers because they work well in practice.  These patterns have been documented by developers over time so that useful ways of organizing and writing good parallel code can be learned by new programmers (and even seasoned veterans).</p>
<div class="section" id="an-organization-of-parallel-patterns">
<h2>An organization of parallel patterns<a class="headerlink" href="#an-organization-of-parallel-patterns" title="Permalink to this headline">¶</a></h2>
<p>When writing parallel programs, developers use patterns that can be grouped into two main categories:</p>
<ol class="arabic simple">
<li>Strategies</li>
<li>Concurrent Execution Mechanisms</li>
</ol>
<div class="section" id="strategies">
<h3>Strategies<a class="headerlink" href="#strategies" title="Permalink to this headline">¶</a></h3>
<p>When you set out to write a program, whether it is parallel or not, you should be considering two primary strategic considerations:</p>
<ol class="arabic simple">
<li>What <em>algorithmic strategies</em> to use</li>
<li>Given the algorithmic strategies, what <em>implementation strategies</em> to use</li>
</ol>
<p>In the examples in this document we introduce some well-used patterns for both algorithmic strategies and implementation strategies.  Parallel algorithmic strategies primarily have to do with making choices about what tasks can be done concurrently by multiple processing units executing concurrently.  Parallel programs often make use of several patterns of implementation strategies.  Some of these patterns contribute to the overall structure of the program, and others are concerned with how the data that is being computed by multiple processing units is structured.  As you will see, the patternlets introduce more algorithmic strategy patterns and program structure implementation strategy patterns than data structure implementation strategy patterns.</p>
</div>
<div class="section" id="concurrent-execution-mechanisms">
<h3>Concurrent Execution Mechanisms<a class="headerlink" href="#concurrent-execution-mechanisms" title="Permalink to this headline">¶</a></h3>
<p>There are a number of parallel code patterns that are closely related to the system or hardware that a program is being written for and the software library used to enable parallelism, or concurrent execution.  These <em>concurrent execution</em> patterns fall into two major categories:</p>
<ol class="arabic simple">
<li><em>Process/Thread control</em> patterns, which dictate how the processing units of parallel execution on the hardware (either a process or a thread, depending on the hardware and software used) are controlled at run time.  For the patternlets described in this document, the software libraries that provide system parallelism have these patterns built into them, so they will be hidden from the programmer.</li>
<li><em>Coordination</em> patterns, which set up how multiple concurrently running tasks on processing units coordinate to complete the parallel computation desired.</li>
</ol>
<p>In parallel processing, most software uses one of
two major <em>coordination patterns</em>:</p>
<blockquote>
<div><ol class="arabic simple">
<li><strong>message passing</strong> between concurrent processes on either single multiprocessor machines or clusters of distributed computers, and</li>
<li><strong>mutual exclusion</strong> between threads executing concurrently on a single shared memory system.</li>
</ol>
</div></blockquote>
<p>These two types of computation are often realized using two very popular C/C++ libraries:</p>
<blockquote>
<div><ol class="arabic simple">
<li>MPI, or Message Passing Interface, for message passing.</li>
<li>OpenMP for threaded, shared memory applications.</li>
</ol>
</div></blockquote>
<p>OpenMP is built on a lower-level POSIX library called Pthreads, which can also be used by itself on shared memory systems.</p>
<p>A third emerging type of parallel implementation involves a <em>hybrid computation</em> that uses both of the above patterns together, using a cluster of computers, each of which executes multiple threads.  This type of hybrid program often uses MPI and OpenMP together in one program, which runs on multiple computers in a cluster.</p>
<p>This document is split into chapters of examples.  There are examples for message passing using MPI and shared memory using OpenMP.
(In the future we will include shared memory examples using Pthreads, and hybrid computations using a combination of MPI and OpenMP.)</p>
<p>Most of the examples are illustrated
with the C programming language, using standard popular available libraries. In a few cases, C++
is used to illustrate a particular difference in code execution between the two languages or to make use of a C++ BigInt class.</p>
<p>There are many small examples that serve to illustrate a common pattern.  They are designed for you to try compiling and running on your own to see how they work.  For each example, there are comments within the code to guide you as you try them out.  In many cases, there may be code snippets that you can comment and/or uncomment to see how the execution of the code changes after you do so and re-compile it.</p>
<p>Depending on you interest, you can now explore MPI Patternlets or OpenMP Patternlets.</p>
<p><a class="reference internal" href="MessagePassing/MPI_Patternlets.html"><em>Message Passing Parallel Patternlets</em></a></p>
<p><a class="reference internal" href="SharedMemory/OpenMP_Patternlets.html"><em>Shared Memory Parallel Patternlets in OpenMP</em></a></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Parallel Programming Patterns</a><ul>
<li><a class="reference internal" href="#an-organization-of-parallel-patterns">An organization of parallel patterns</a><ul>
<li><a class="reference internal" href="#strategies">Strategies</a></li>
<li><a class="reference internal" href="#concurrent-execution-mechanisms">Concurrent Execution Mechanisms</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Parallel Patternlets</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="MessagePassing/MPI_Patternlets.html"
                        title="next chapter">Message Passing Parallel Patternlets</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="MessagePassing/MPI_Patternlets.html" title="Message Passing Parallel Patternlets"
             >next</a></li>
        <li class="right" >
          <a href="index.html" title="Parallel Patternlets"
             >previous</a> |</li>
        <li><a href="index.html">Parallel Patternlets</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>