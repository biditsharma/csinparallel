
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Master Worker Pattern and Message Passing &#8212; Parallel Patternlets</title>
    
    <link rel="stylesheet" href="../_static/csip.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Broadcast" href="Broadcast.html" />
    <link rel="prev" title="Message Passing Parallel Patternlets" href="MPI_Patternlets.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Broadcast.html" title="Broadcast"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="MPI_Patternlets.html" title="Message Passing Parallel Patternlets"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="MPI_Patternlets.html" accesskey="U">Message Passing Parallel Patternlets</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="master-worker-pattern-and-message-passing">
<h1>Master Worker Pattern and Message Passing<a class="headerlink" href="#master-worker-pattern-and-message-passing" title="Permalink to this headline">¶</a></h1>
<div class="section" id="single-program-multiple-data">
<h2>00. Single Program, Multiple Data<a class="headerlink" href="#single-program-multiple-data" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/00.spmd/spmd.c</em></p>
<p><em>Build inside 00.spmd directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">spmd</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 00.spmd directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">spmd</span>
</pre></div>
</div>
<p>First let us illustrate the basic components of an MPI program,
which by its nature uses a single program that runs on each process.
Note what gets printed is different for each process, thus the
processes using this one single program can have different data values
for its variables.  This is why we call it single program, multiple data.</p>
<p>On the command line, <em>mpirun</em> tells the system to start &lt;number of processes&gt;
instances of the program. The call to <em>MPI_INIT</em> on line 25 tells the MPI
system to setup. This includes allocating storage for message buffers and
deciding the rank each process receives. <em>MPI_INIT</em> also defines a communicator
called <em>MPI_COMM_WORLD</em>. A communicator is a group of processes that can
communicate with each other by sending messages. The <em>MPI_Finalize</em> command
tells the MPI system that we are finished and it deallocates MPI resources.</p>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>Can you determine the purpose of the <em>MPI_Comm_rank</em> function and
<em>MPI_Comm_size</em> function? How is the communicator related to these functions?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* spmd.c</span>
<span class="cm"> * ... illustrates the single program multiple data</span>
<span class="cm"> *      (SPMD) pattern using basic MPI commands.</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np 4 ./spmd</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run.</span>
<span class="cm"> * - Compare source code to output.</span>
<span class="cm"> * - Rerun, using varying numbers of processes</span>
<span class="cm"> *    (i.e., vary the argument to &#39;mpirun -np&#39;).</span>
<span class="cm"> * - Explain what &quot;multiple data&quot; values this</span>
<span class="cm"> *    &quot;single program&quot; is generating.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;   // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;     // MPI functions</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numProcesses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">myHostName</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcesses</span><span class="p">);</span>
    <span class="n">MPI_Get_processor_name</span> <span class="p">(</span><span class="n">myHostName</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">length</span><span class="p">);</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Greetings from process #%d of %d on %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
             <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">myHostName</span><span class="p">);</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="the-master-worker-implementation-strategy-pattern">
<h2>01. The Master-Worker Implementation Strategy Pattern<a class="headerlink" href="#the-master-worker-implementation-strategy-pattern" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/01.masterWorker/masterWorker.c</em></p>
<p><em>Build inside 01.masterWorker directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">masterWorker</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 01.masterWorker directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">masterWorker</span>
</pre></div>
</div>
<p>The master worker pattern is illustrated in this simple example.  The pattern
consists of one process, called the master, executing one block of code while
the rest of the processes, called workers, are executing a different block of code.</p>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* masterWorker.c</span>
<span class="cm"> * ... illustrates the basic master-worker pattern in MPI ...</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./masterWorker</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run the program, varying N from 1 through 8.</span>
<span class="cm"> * - Explain what stays the same and what changes as the</span>
<span class="cm"> *    number of processes changes.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numWorkers</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="kt">char</span> <span class="n">hostName</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>

  <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
  <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numWorkers</span><span class="p">);</span>
  <span class="n">MPI_Get_processor_name</span> <span class="p">(</span><span class="n">hostName</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">length</span><span class="p">);</span>

  <span class="k">if</span> <span class="p">(</span> <span class="n">id</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>  <span class="c1">// process 0 is the master </span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Greetings from the master, #%d (%s) of %d processes</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
             <span class="n">id</span><span class="p">,</span> <span class="n">hostName</span><span class="p">,</span> <span class="n">numWorkers</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>          <span class="c1">// processes with ids &gt; 0 are workers </span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Greetings from a worker, #%d (%s) of %d processes</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
             <span class="n">id</span><span class="p">,</span> <span class="n">hostName</span><span class="p">,</span> <span class="n">numWorkers</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="n">MPI_Finalize</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="message-passing-deadlock-using-send-receive-of-a-single-value">
<h2>02. Message passing deadlock, using Send-Receive of a single value<a class="headerlink" href="#message-passing-deadlock-using-send-receive-of-a-single-value" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/02.messagePassingDeadlock/messagePassingDeadlock.c</em></p>
<p><em>Build inside 02.messagePassingDeadlock directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">messagePassingDeadlock</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 02.messagePassingDeadlock directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">messagePassingDeadlock</span>
</pre></div>
</div>
<p>This example shows the pattern of sending and receiving messages between
various processes. The following code displays 2-way communication between
pairs with message passing occurring between pairs of odd and even rank processes.</p>
<p>(rank 0, rank 1), (rank 2, rank 3), (rank 4, rank 5), … ,</p>
<p>The message that is being passed is the rank of the current process.
Conceptually, the running code is executing like this, where time is moving
from top to bottom:</p>
<a class="reference internal image-reference" href="../_images/Deadlock.png"><img alt="../_images/Deadlock.png" src="../_images/Deadlock.png" style="width: 500px;" /></a>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>Can you explain why this program deadlocks and how we might avoid this
situation?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* messagePassingDeadlock.c</span>
<span class="cm"> * ... illustrates deadlock with MPI_Send() and MPI_Recv() commands...</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> * Modified by Hannah Sonsalla, Macalester College 2017.</span>
<span class="cm"> * </span>
<span class="cm"> * Usage: mpirun -np N ./messagePassing</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, using more than one process.</span>
<span class="cm"> * - Use source code to trace execution.</span>
<span class="cm"> * - Why does this fail?</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">odd</span><span class="p">(</span><span class="kt">int</span> <span class="n">number</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span><span class="p">;</span> <span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numProcesses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">sendValue</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">receivedValue</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcesses</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">numProcesses</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">sendValue</span> <span class="o">=</span> <span class="n">id</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span> <span class="n">odd</span><span class="p">(</span><span class="n">id</span><span class="p">)</span> <span class="p">)</span> <span class="p">{</span>  <span class="c1">// odd processors send, then receive</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">receivedValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sendValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>          <span class="c1">// even processors receive, then send</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">receivedValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sendValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d of %d computed %d and received %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
                <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">sendValue</span><span class="p">,</span> <span class="n">receivedValue</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span> <span class="o">!</span><span class="n">id</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// only process 0 does this part</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Please run this program using -np N where N is positive and even.</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="message-passing-1-using-send-receive-of-a-single-value">
<h2>03. Message passing 1, using Send-Receive of a single value<a class="headerlink" href="#message-passing-1-using-send-receive-of-a-single-value" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/03.messagePassing/messagePassing.c</em></p>
<p><em>Build inside 03.messagePassing directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">messagePassing</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 03.messagePassing directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">messagePassing</span>
</pre></div>
</div>
<p>This is an extension of the previous example that highlights how a deadlock
might occur from message passing. We will show one possible solution for
fixing this problem. We can avoid a deadlock by simply reversing
the order of one of the receive/send pairs.  Now, we have one receive/send
pair and one send/receive pair. As shown in the diagram below, where time
is moving from top to bottom, even processes are receive/send pairs and
odd processes are send/receive pairs.</p>
<a class="reference internal image-reference" href="../_images/MessagePassing.png"><img alt="../_images/MessagePassing.png" src="../_images/MessagePassing.png" style="width: 700px;" /></a>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>Compile and run using 4, 6, 8 and 10 processes. Note that the program
now completes without deadlocking. Why does reversing one of the receive/send
pairs allow us to avoid the deadlock situation all together?</p>
<p>Run using 5 processes. What process threw an error and why was an error thrown?
<em>Hint:</em> See diagram below.</p>
</div>
<a class="reference internal image-reference" href="../_images/MessagePassingOdd.png"><img alt="../_images/MessagePassingOdd.png" src="../_images/MessagePassingOdd.png" style="width: 700px;" /></a>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* messagePassing.c</span>
<span class="cm"> * ... illustrates the use of the MPI_Send() and MPI_Recv() commands...</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> * Modified by Hannah Sonsalla, Macalester College 2017.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./messagePassing</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, using N = 4, 6, 8, and 10 processes.</span>
<span class="cm"> * - Use source code to trace execution.</span>
<span class="cm"> * - Explain what each process:</span>
<span class="cm"> * -- sends</span>
<span class="cm"> * -- receives</span>
<span class="cm"> * -- outputs.</span>
<span class="cm"> * - Run using N = 5 processes. What happens?</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">odd</span><span class="p">(</span><span class="kt">int</span> <span class="n">number</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span><span class="p">;</span> <span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numProcesses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">sendValue</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">receivedValue</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcesses</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">numProcesses</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">sendValue</span> <span class="o">=</span> <span class="n">id</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span> <span class="n">odd</span><span class="p">(</span><span class="n">id</span><span class="p">)</span> <span class="p">)</span> <span class="p">{</span>  <span class="c1">// odd processors send, then receive</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sendValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">receivedValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>          <span class="c1">// even processors receive, then send</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">receivedValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sendValue</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d of %d computed %d and received %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
                <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">sendValue</span><span class="p">,</span> <span class="n">receivedValue</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span> <span class="o">!</span><span class="n">id</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// only process 0 does this part</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Please run this program using -np N where N is positive and even.</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="message-passing-2-using-send-receive-of-an-array-of-values">
<h2>04. Message passing 2,  using Send-Receive of an array of values<a class="headerlink" href="#message-passing-2-using-send-receive-of-an-array-of-values" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/04.messagePassing2/messagePassing2.c</em></p>
<p><em>Build inside 04.messagePassing2 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">messagePassing2</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 04.messagePassing2 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">messagePassing2</span>
</pre></div>
</div>
<p>The messages sent and received by processes can be of types other than
integers. Here the message that is being passed is a string (array of chars).
This example follows the previous message passing examples in that it
passes strings between pairs of odd and even rank processes.</p>
<p>We use dynamic memory allocation for the sendString and receivedString. Dynamic
memory allocation lets a program obtain more memory space while running
or release memory space if it is not needed. We can use this type of
memory allocation to manually handle memory space. The function <em>malloc</em> on
lines 36 and 37 allocates a block of SIZE bytes of memory for the
sendString and receivedString.</p>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>What is the free function doing on lines 56 and 57?
Why must we apply the free function to both sendString and receivedString?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* messagePassing2.c</span>
<span class="cm"> * ... illustrates using MPI_Send() and MPI_Recv() commands on arrays...</span>
<span class="cm"> * While this example sends and receives char arrays (strings),</span>
<span class="cm"> *  the same approach works on arrays of numbers or other types.</span>
<span class="cm"> * Joel Adams, Calvin College, September 2013.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./messagePassing2</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, varying N: 1, 2, 4, 8.</span>
<span class="cm"> * - Trace execution using source code.</span>
<span class="cm"> * - Compare to messagePassing1.c; note send/receive differences.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;   // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;     // MPI</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;  // malloc()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;string.h&gt;  // strlen()</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">odd</span><span class="p">(</span><span class="kt">int</span> <span class="n">number</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span><span class="p">;</span> <span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numProcesses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span> <span class="n">sendString</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span> <span class="n">receivedString</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">hostName</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
    <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="o">+</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">);</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcesses</span><span class="p">);</span>
    <span class="n">MPI_Get_processor_name</span> <span class="p">(</span><span class="n">hostName</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">length</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">numProcesses</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">odd</span><span class="p">(</span><span class="n">numProcesses</span><span class="p">)</span> <span class="p">)</span> <span class="p">{</span>
        <span class="n">sendString</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span> <span class="n">SIZE</span> <span class="p">);</span>
        <span class="n">receivedString</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span> <span class="n">SIZE</span> <span class="p">);</span>
        <span class="c1">// sprintf: write to string</span>
        <span class="n">sprintf</span><span class="p">(</span><span class="n">sendString</span><span class="p">,</span> <span class="s">&quot;Process %d is on host </span><span class="se">\&quot;</span><span class="s">%s</span><span class="se">\&quot;</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="n">hostName</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span> <span class="n">odd</span><span class="p">(</span><span class="n">id</span><span class="p">)</span> <span class="p">)</span> <span class="p">{</span>  <span class="c1">// odd processes send, then receive</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="n">sendString</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">sendString</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                       <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">receivedString</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="n">id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>          <span class="c1">// even processes receive, then send</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">receivedString</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                       <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
            <span class="n">MPI_Send</span><span class="p">(</span><span class="n">sendString</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">sendString</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                       <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Process %d of %d received the message:</span><span class="se">\n\t</span><span class="s">&#39;%s&#39;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
                <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">receivedString</span><span class="p">);</span>

        <span class="n">free</span><span class="p">(</span><span class="n">sendString</span><span class="p">);</span>
        <span class="n">free</span><span class="p">(</span><span class="n">receivedString</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span> <span class="o">!</span><span class="n">id</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// only process 0 does this part</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Please run this program using -np N where N is positive and even.</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="message-passing-3-using-send-receive-with-master-worker-pattern">
<h2>05. Message passing 3, using Send-Receive with master-worker pattern<a class="headerlink" href="#message-passing-3-using-send-receive-with-master-worker-pattern" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/05.messagePassing3/messagePassing3.c</em></p>
<p><em>Build inside 05.messagePassing3 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">make</span> <span class="n">messagePassing3</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 05.messagePassing3 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">messagePassing3</span>
</pre></div>
</div>
<p>Sending and receiving typically occurs in pairs. We will investigate a scenario
in which this is <em>not</em> the case. Suppose we have four processes, 0 through 3,
all of which are arranged in a “ring”. We want each process to communicate a
modified string containing sequential ranks to the next process. Process 0 begins
by sending its rank to process 1. Process 1 receives a string containing
a 0. Next, process 1 adds its rank to the string and sends the string to process
2. Then, process 2 receives the string containing 0 and 1, and so on. This
continues until process 0 receives the final string from the last process (process with the largest rank). Thus, process 0 is the beginning and ending
location of the “ring”. This type of circular dependency can be thought of like this:</p>
<a class="reference internal image-reference" href="../_images/CircularDependancy.png"><img alt="../_images/CircularDependancy.png" src="../_images/CircularDependancy.png" style="width: 800px;" /></a>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>In our example, when will this communication pattern fail to execute properly
and finish? What is needed to be able to guarantee completion?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79</pre></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* messagePassing3.c</span>
<span class="cm"> * ... illustrates the use of MPI_Send() and MPI_Recv(),</span>
<span class="cm"> *      in combination with the master-worker pattern.</span>
<span class="cm"> *</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./messagePassing3</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Run the program, varying the value of N from 1-8.</span>
<span class="cm"> * - Explain the behavior you observe.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;    // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;string.h&gt;   // strlen()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;      // MPI</span><span class="cp"></span>

<span class="cp">#define MAX 256</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numProcesses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">sendBuffer</span><span class="p">[</span><span class="n">MAX</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sc">&#39;\0&#39;</span><span class="p">};</span>
    <span class="kt">char</span> <span class="n">recvBuffer</span><span class="p">[</span><span class="n">MAX</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sc">&#39;\0&#39;</span><span class="p">};</span>
    <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcesses</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">numProcesses</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span> <span class="n">id</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>                              <span class="c1">// master:</span>
            <span class="n">sprintf</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">,</span> <span class="s">&quot;%d&quot;</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>            <span class="c1">//  create msg</span>

            <span class="n">MPI_Send</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">,</span>                      <span class="c1">//  msg sent</span>
                      <span class="n">strlen</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>         <span class="c1">//  num chars + NULL</span>
                      <span class="n">MPI_CHAR</span><span class="p">,</span>                       <span class="c1">//  type</span>
                      <span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>                           <span class="c1">//  destination</span>
                      <span class="mi">1</span><span class="p">,</span>                              <span class="c1">//  tag</span>
                      <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>                <span class="c1">//  communicator</span>

            <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">recvBuffer</span><span class="p">,</span>                      <span class="c1">//  msg received</span>
                      <span class="n">MAX</span><span class="p">,</span>                            <span class="c1">//  buffer size</span>
                      <span class="n">MPI_CHAR</span><span class="p">,</span>                       <span class="c1">//  type</span>
                      <span class="n">numProcesses</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>                 <span class="c1">//  sender</span>
                      <span class="mi">1</span><span class="p">,</span>                              <span class="c1">//  tag</span>
                      <span class="n">MPI_COMM_WORLD</span><span class="p">,</span>                 <span class="c1">//  communicator</span>
                      <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>                       <span class="c1">//  recv status</span>

            <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process #%d of %d received %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="c1">// show msg</span>
                    <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">recvBuffer</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>                                      <span class="c1">// workers:</span>
            <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">recvBuffer</span><span class="p">,</span>                      <span class="c1">//  msg received</span>
                      <span class="n">MAX</span><span class="p">,</span>                            <span class="c1">//  buffer size</span>
                      <span class="n">MPI_CHAR</span><span class="p">,</span>                       <span class="c1">//  type</span>
                      <span class="n">MPI_ANY_SOURCE</span><span class="p">,</span>                 <span class="c1">//  sender (anyone)</span>
                      <span class="mi">1</span><span class="p">,</span>                              <span class="c1">//  tag</span>
                      <span class="n">MPI_COMM_WORLD</span><span class="p">,</span>                 <span class="c1">//  communicator</span>
                      <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>                       <span class="c1">//  recv status</span>

            <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process #%d of %d received %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="c1">// show msg</span>
                    <span class="n">id</span><span class="p">,</span> <span class="n">numProcesses</span><span class="p">,</span> <span class="n">recvBuffer</span><span class="p">);</span>

            <span class="c1">// build msg to send by appending id to msg received</span>
            <span class="n">sprintf</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">,</span> <span class="s">&quot;%s %d&quot;</span><span class="p">,</span> <span class="n">recvBuffer</span><span class="p">,</span> <span class="n">id</span><span class="p">);</span>

            <span class="n">MPI_Send</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">,</span>                      <span class="c1">//  msg to send</span>
                      <span class="n">strlen</span><span class="p">(</span><span class="n">sendBuffer</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>         <span class="c1">//  num chars + NULL</span>
                      <span class="n">MPI_CHAR</span><span class="p">,</span>                       <span class="c1">//  type</span>
                      <span class="p">(</span><span class="n">id</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">numProcesses</span><span class="p">,</span>          <span class="c1">//  destination</span>
                      <span class="mi">1</span><span class="p">,</span>                              <span class="c1">//  tag</span>
                      <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>                <span class="c1">//  communicator</span>
        <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Please run this program with at least 2 processes</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Master Worker Pattern and Message Passing</a><ul>
<li><a class="reference internal" href="#single-program-multiple-data">00. Single Program, Multiple Data</a></li>
<li><a class="reference internal" href="#the-master-worker-implementation-strategy-pattern">01. The Master-Worker Implementation Strategy Pattern</a></li>
<li><a class="reference internal" href="#message-passing-deadlock-using-send-receive-of-a-single-value">02. Message passing deadlock, using Send-Receive of a single value</a></li>
<li><a class="reference internal" href="#message-passing-1-using-send-receive-of-a-single-value">03. Message passing 1, using Send-Receive of a single value</a></li>
<li><a class="reference internal" href="#message-passing-2-using-send-receive-of-an-array-of-values">04. Message passing 2,  using Send-Receive of an array of values</a></li>
<li><a class="reference internal" href="#message-passing-3-using-send-receive-with-master-worker-pattern">05. Message passing 3, using Send-Receive with master-worker pattern</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="MPI_Patternlets.html"
                        title="previous chapter">Message Passing Parallel Patternlets</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="Broadcast.html"
                        title="next chapter">Broadcast</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Broadcast.html" title="Broadcast"
             >next</a></li>
        <li class="right" >
          <a href="MPI_Patternlets.html" title="Message Passing Parallel Patternlets"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="MPI_Patternlets.html" >Message Passing Parallel Patternlets</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.2.
    </div>
  </body>
</html>