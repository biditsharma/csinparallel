
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Collective Communication &#8212; Parallel Patternlets</title>
    <link rel="stylesheet" href="../_static/csip.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Barrier Synchronization, Timing and Tags" href="Barrier_Tags.html" />
    <link rel="prev" title="Broadcast" href="Broadcast.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Barrier_Tags.html" title="Barrier Synchronization, Timing and Tags"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="Broadcast.html" title="Broadcast"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="MPI_Patternlets.html" accesskey="U">Message Passing Parallel Patternlets</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="collective-communication">
<h1>Collective Communication<a class="headerlink" href="#collective-communication" title="Permalink to this headline">¶</a></h1>
<p>With independent, often distributed processes, there is a need in many
program situations to have all the processes communicating with each other,
usually by sharing data, either before or after independent simultaneous
computations that each process performs. Here we see simple examples of these
collective communication patterns.</p>
<div class="section" id="collective-communication-reduction">
<h2>12. Collective Communication: Reduction<a class="headerlink" href="#collective-communication-reduction" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/12.reduction/reduction.c</em></p>
<p><em>Build inside 12.reduction directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">reduction</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 12.reduction directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">reduction</span>
</pre></div>
</div>
<p>Once processes have performed independent concurrent computations, possibly
on some portion of decomposed data, it is quite common to then <em>reduce</em>
those individual computations into one value. This example shows a simple
calculation done by each process being reduced to a sum and a maximum.
In this example, MPI, has built-in computations, indicated by MPI_SUM and
MPI_MAX in the following code. With four processes, the code is implemented
like this:</p>
<a class="reference internal image-reference" href="../_images/Reduction.png"><img alt="../_images/Reduction.png" src="../_images/Reduction.png" style="width: 800px;" /></a>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* reduction.c</span>
<span class="cm">* ... illustrates the use of MPI_Reduce()...</span>
<span class="cm">* Joel Adams, Calvin College, November 2009.</span>
<span class="cm">*</span>
<span class="cm">* Usage: mpirun -np N ./reduction</span>
<span class="cm">*</span>
<span class="cm">* Exercise:</span>
<span class="cm">* - Compile and run, varying N: 4, 6, 8, 10.</span>
<span class="cm">* - Explain behavior of MPI_Reduce().</span>
<span class="cm">*/</span>

<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">numProcs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">myRank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcs</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>

    <span class="n">square</span> <span class="o">=</span> <span class="p">(</span><span class="n">myRank</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">myRank</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d computed %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">myRank</span><span class="p">,</span> <span class="n">square</span><span class="p">);</span>

    <span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">square</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sum</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MPI_SUM</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">square</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">max</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MPI_MAX</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">The sum of the squares is %d</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">sum</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;The max of the squares is %d</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="id1">
<h2>13. Collective Communication: Reduction<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/13.reduction2/reduction2.c</em></p>
<p><em>Build inside 13.reduction2 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">reduction2</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 13.reduction2 directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">reduction2</span>
</pre></div>
</div>
<p>Here is a second reduction example using arrays of data.</p>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>Can you explain the reduction, <cite>MPI_reduce</cite>, in terms of srcArr and destArr?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* reduction2.c</span>
<span class="cm"> * ... illustrates the use of MPI_Reduce() using arrays...</span>
<span class="cm"> * Joel Adams, Calvin College, January 2015.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np 4 ./reduction2</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, comparing output to source code.</span>
<span class="cm"> * - Uncomment the &#39;commented out&#39; call to printArray.</span>
<span class="cm"> * - Save, recompile, rerun, comparing output to source code.</span>
<span class="cm"> * - Explain behavior of MPI_Reduce() in terms of</span>
<span class="cm"> *     srcArr and destArr.</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>

<span class="cp">#define ARRAY_SIZE 5</span>

<span class="kt">void</span> <span class="nf">printArray</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrayName</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">array</span><span class="p">,</span> <span class="kt">int</span> <span class="n">SIZE</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">myRank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">srcArr</span><span class="p">[</span><span class="n">ARRAY_SIZE</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
    <span class="kt">int</span> <span class="n">destArr</span><span class="p">[</span><span class="n">ARRAY_SIZE</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Before reduction: &quot;</span><span class="p">);</span>
        <span class="n">printArray</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;destArr&quot;</span><span class="p">,</span> <span class="n">destArr</span><span class="p">,</span> <span class="n">ARRAY_SIZE</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ARRAY_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">srcArr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">myRank</span> <span class="o">*</span> <span class="n">i</span><span class="p">;</span>
    <span class="p">}</span>

   <span class="n">printArray</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;srcArr&quot;</span><span class="p">,</span> <span class="n">srcArr</span><span class="p">,</span> <span class="n">ARRAY_SIZE</span><span class="p">);</span>

    <span class="n">MPI_Reduce</span><span class="p">(</span><span class="n">srcArr</span><span class="p">,</span> <span class="n">destArr</span><span class="p">,</span> <span class="n">ARRAY_SIZE</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">MPI_SUM</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">After reduction:  &quot;</span><span class="p">);</span>
        <span class="n">printArray</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;destArr&quot;</span><span class="p">,</span> <span class="n">destArr</span><span class="p">,</span> <span class="n">ARRAY_SIZE</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">MPI_Finalize</span><span class="p">();</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* utility to display an array</span>
<span class="cm"> * params: id, the rank of the current process</span>
<span class="cm"> *         arrayName, the name of the array being displayed</span>
<span class="cm"> *         array, the array being displayed</span>
<span class="cm"> *         SIZE, the number of items in array.</span>
<span class="cm"> * postcondition:</span>
<span class="cm"> *         the id, name, and items in array have been printed to stdout.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">printArray</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrayName</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span> <span class="n">array</span><span class="p">,</span> <span class="kt">int</span> <span class="n">SIZE</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d, %s: [&quot;</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="n">arrayName</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%3d&quot;</span><span class="p">,</span> <span class="n">array</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">SIZE</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&quot;,&quot;</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;]</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<div class="topic">
<p class="topic-title first">Further Exploration:</p>
<p>This useful <a class="reference external" href="http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/">MPI tutorial</a> explains other
reduction operations that can be performed. You could use the above code or
the previous examples to experiment with some of these.</p>
</div>
</div>
<div class="section" id="collective-communication-scatter-for-message-passing-data-decomposition">
<h2>14. Collective communication: Scatter for message-passing data decomposition<a class="headerlink" href="#collective-communication-scatter-for-message-passing-data-decomposition" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/14.scatter/scatter.c</em></p>
<p><em>Build inside 14.scatter directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">scatter</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 14.scatter directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">scatter</span>
</pre></div>
</div>
<p>If processes can independently work on portions of a larger data array
using the geometric data decomposition pattern, the scatter pattern can be
used to ensure that each process receives a copy of its portion of the array.
Process 0 gets the first chunk, process 1 gets the second chunk and so on until
the entire array has been distributed.</p>
<a class="reference internal image-reference" href="../_images/Scatter.png"><img alt="../_images/Scatter.png" src="../_images/Scatter.png" style="width: 700px;" /></a>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>What previous data decomposition pattern is this similar to?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* scatter.c</span>
<span class="cm"> * ... illustrates the use of MPI_Scatter()...</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./scatter</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, varying N: 1, 2, 4, 8</span>
<span class="cm"> * - Trace execution through source code.</span>
<span class="cm"> * - Explain behavior/effect of MPI_Scatter().</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;      // MPI</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;    // printf(), etc.</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;   // malloc()</span><span class="cp"></span>

<span class="kt">void</span> <span class="nf">print</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrName</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">arr</span><span class="p">,</span> <span class="kt">int</span> <span class="n">arrSize</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">MAX</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
    <span class="kt">int</span><span class="o">*</span> <span class="n">arrSend</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="kt">int</span><span class="o">*</span> <span class="n">arrRcv</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">numProcs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">myRank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numSent</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>

    <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>                            <span class="c1">// initialize</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcs</span><span class="p">);</span>
    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>                                 <span class="c1">// master process:</span>
        <span class="n">arrSend</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span> <span class="n">MAX</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">);</span>  <span class="c1">//  allocate array1</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">MAX</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>                <span class="c1">//  load with values</span>
            <span class="n">arrSend</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">11</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">print</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;arrSend&quot;</span><span class="p">,</span> <span class="n">arrSend</span><span class="p">,</span> <span class="n">MAX</span><span class="p">);</span>        <span class="c1">//  display array1</span>
    <span class="p">}</span>
     
    <span class="n">numSent</span> <span class="o">=</span> <span class="n">MAX</span> <span class="o">/</span> <span class="n">numProcs</span><span class="p">;</span>                          <span class="c1">// all processes:</span>
    <span class="n">arrRcv</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span> <span class="n">numSent</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">);</span>   <span class="c1">//  allocate array2</span>

    <span class="n">MPI_Scatter</span><span class="p">(</span><span class="n">arrSend</span><span class="p">,</span> <span class="n">numSent</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">arrRcv</span><span class="p">,</span>     <span class="c1">//  scatter array1 </span>
                 <span class="n">numSent</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span> <span class="c1">//   into array2</span>

    <span class="n">print</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;arrRcv&quot;</span><span class="p">,</span> <span class="n">arrRcv</span><span class="p">,</span> <span class="n">numSent</span><span class="p">);</span>          <span class="c1">// display array2</span>

    <span class="n">free</span><span class="p">(</span><span class="n">arrSend</span><span class="p">);</span>                                     <span class="c1">// clean up</span>
    <span class="n">free</span><span class="p">(</span><span class="n">arrRcv</span><span class="p">);</span>
    <span class="n">MPI_Finalize</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">print</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrName</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">arr</span><span class="p">,</span> <span class="kt">int</span> <span class="n">arrSize</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d, %s: &quot;</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="n">arrName</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">arrSize</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot; %d&quot;</span><span class="p">,</span> <span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="p">}</span>

</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="collective-communication-gather-for-message-passing-data-decomposition">
<h2>15. Collective communication: Gather for message-passing data decomposition<a class="headerlink" href="#collective-communication-gather-for-message-passing-data-decomposition" title="Permalink to this headline">¶</a></h2>
<p><em>file: patternlets/MPI/15.gather/gather.c</em></p>
<p><em>Build inside 15.gather directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">gather</span>
</pre></div>
</div>
<p><em>Execute on the command line inside 15.gather directory:</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="o">&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">processes</span><span class="o">&gt;</span> <span class="o">./</span><span class="n">gather</span>
</pre></div>
</div>
<p>If processes can independently work on portions of a larger data array
using the geometric data decomposition pattern,
the gather pattern can be used to ensure that each process sends
a copy of its portion of the array back to the root, or master process.
Thus, gather is the reverse of scatter. Here is the idea:</p>
<a class="reference internal image-reference" href="../_images/Gather.png"><img alt="../_images/Gather.png" src="../_images/Gather.png" style="width: 750px;" /></a>
<div class="topic">
<p class="topic-title first">To do:</p>
<p>Find documentation for the MPI function MPI_Gather.
Make sure that you know what each parameter is for.
Why are the second and fourth parameters in our example
both SIZE? Can you explain what this means in terms of
MPI_Gather?</p>
</div>
<div class="highlight-c"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="cm">/* gather.c</span>
<span class="cm"> * ... illustrates the use of MPI_Gather()...</span>
<span class="cm"> * Joel Adams, Calvin College, November 2009.</span>
<span class="cm"> *</span>
<span class="cm"> * Usage: mpirun -np N ./gather</span>
<span class="cm"> *</span>
<span class="cm"> * Exercise:</span>
<span class="cm"> * - Compile and run, varying N: 1, 2, 4, 8.</span>
<span class="cm"> * - Trace execution through source.</span>
<span class="cm"> * - Explain behavior of MPI_Gather().</span>
<span class="cm"> */</span>

<span class="cp">#include</span> <span class="cpf">&lt;mpi.h&gt;       // MPI</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;     // printf()</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;stdlib.h&gt;    // malloc()</span><span class="cp"></span>

<span class="kt">void</span> <span class="nf">print</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrName</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">arr</span><span class="p">,</span> <span class="kt">int</span> <span class="n">arrSize</span><span class="p">);</span>

<span class="cp">#define SIZE 3</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
   <span class="kt">int</span>  <span class="n">computeArray</span><span class="p">[</span><span class="n">SIZE</span><span class="p">];</span>                          <span class="c1">// array1</span>
   <span class="kt">int</span><span class="o">*</span> <span class="n">gatherArray</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>                          <span class="c1">// array2</span>
   <span class="kt">int</span>  <span class="n">numProcs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">myRank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">totalGatheredVals</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>

   <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>                           <span class="c1">// initialize</span>
   <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numProcs</span><span class="p">);</span>
   <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>
                                                     <span class="c1">// all processes:</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>                  <span class="c1">//  load array1 with</span>
      <span class="n">computeArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">myRank</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">i</span><span class="p">;</span>             <span class="c1">//   3 distinct values</span>
   <span class="p">}</span>

   <span class="n">print</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;computeArray&quot;</span><span class="p">,</span> <span class="n">computeArray</span><span class="p">,</span>       <span class="c1">//  show array1</span>
           <span class="n">SIZE</span><span class="p">);</span>

   <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>                                <span class="c1">// master:</span>
      <span class="n">totalGatheredVals</span> <span class="o">=</span> <span class="n">SIZE</span> <span class="o">*</span> <span class="n">numProcs</span><span class="p">;</span>           <span class="c1">//  allocate array2</span>
      <span class="n">gatherArray</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span> <span class="n">totalGatheredVals</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">);</span>
   <span class="p">}</span>

   <span class="n">MPI_Gather</span><span class="p">(</span><span class="n">computeArray</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span>           <span class="c1">//  gather array1 vals</span>
               <span class="n">gatherArray</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span>           <span class="c1">//   into array2</span>
               <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>                   <span class="c1">//   at master process</span>

   <span class="k">if</span> <span class="p">(</span><span class="n">myRank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>                                <span class="c1">// master process:</span>
      <span class="n">print</span><span class="p">(</span><span class="n">myRank</span><span class="p">,</span> <span class="s">&quot;gatherArray&quot;</span><span class="p">,</span>                   <span class="c1">//  show array2</span>
             <span class="n">gatherArray</span><span class="p">,</span> <span class="n">totalGatheredVals</span><span class="p">);</span>
      <span class="n">free</span><span class="p">(</span><span class="n">gatherArray</span><span class="p">);</span>                             <span class="c1">// clean up</span>
   <span class="p">}</span>


   <span class="n">MPI_Finalize</span><span class="p">();</span>
   <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">print</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">arrName</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">arr</span><span class="p">,</span> <span class="kt">int</span> <span class="n">arrSize</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Process %d, %s: &quot;</span><span class="p">,</span> <span class="n">id</span><span class="p">,</span> <span class="n">arrName</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">arrSize</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot; %d&quot;</span><span class="p">,</span> <span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/CSInParallel200wide.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Collective Communication</a><ul>
<li><a class="reference internal" href="#collective-communication-reduction">12. Collective Communication: Reduction</a></li>
<li><a class="reference internal" href="#id1">13. Collective Communication: Reduction</a></li>
<li><a class="reference internal" href="#collective-communication-scatter-for-message-passing-data-decomposition">14. Collective communication: Scatter for message-passing data decomposition</a></li>
<li><a class="reference internal" href="#collective-communication-gather-for-message-passing-data-decomposition">15. Collective communication: Gather for message-passing data decomposition</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="Broadcast.html"
                        title="previous chapter">Broadcast</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="Barrier_Tags.html"
                        title="next chapter">Barrier Synchronization, Timing and Tags</a></p>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="Barrier_Tags.html" title="Barrier Synchronization, Timing and Tags"
             >next</a></li>
        <li class="right" >
          <a href="Broadcast.html" title="Broadcast"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Parallel Patternlets</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="MPI_Patternlets.html" >Message Passing Parallel Patternlets</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>