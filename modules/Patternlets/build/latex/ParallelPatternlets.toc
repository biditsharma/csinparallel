\select@language {english}
\contentsline {chapter}{\numberline {1}Source Code}{2}{chapter.1}
\contentsline {chapter}{\numberline {2}Contents:}{3}{chapter.2}
\contentsline {section}{\numberline {2.1}Message Passing Parallel Patternlets}{3}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Source Code}{3}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}0. Hello, World}{3}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}1. The Master-Worker Implementation Strategy Pattern}{4}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}2. Send-Receive (basic message passing pattern)}{4}{subsection.2.1.4}
\contentsline {subsection}{\numberline {2.1.5}3. Data Decomposition: on \emph {slices} using parallel-for}{5}{subsection.2.1.5}
\contentsline {subsection}{\numberline {2.1.6}4. Data Decomposition: on \emph {blocks} using parallel-for}{6}{subsection.2.1.6}
\contentsline {subsection}{\numberline {2.1.7}5. Broadcast: a special form of message passing}{6}{subsection.2.1.7}
\contentsline {subsection}{\numberline {2.1.8}6. Collective Communication: Reduction}{7}{subsection.2.1.8}
\contentsline {subsection}{\numberline {2.1.9}7. Collective communication: Scatter for message-passing data decomposition}{8}{subsection.2.1.9}
\contentsline {subsection}{\numberline {2.1.10}8. Collective communication: Gather for message-passing data decomposition}{9}{subsection.2.1.10}
\contentsline {section}{\numberline {2.2}Shared Memory Parallel Patternlets in OpenMP}{9}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Source Code}{10}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}0. The OMP parallel pragma}{10}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}1. Hello, World: default number of OpenMP threads}{10}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}2. Hello, World}{11}{subsection.2.2.4}
\contentsline {subsection}{\numberline {2.2.5}3. Master-Worker Implementation Strategy}{12}{subsection.2.2.5}
\contentsline {subsection}{\numberline {2.2.6}4. Shared Data Decomposition Pattern: blocking of threads in a parallel for loop}{12}{subsection.2.2.6}
\contentsline {subsection}{\numberline {2.2.7}5. Shared Data Decomposition Pattern: striping of threads in a parallel for loop}{13}{subsection.2.2.7}
\contentsline {subsection}{\numberline {2.2.8}6. Collective Communication: Reduction}{13}{subsection.2.2.8}
\contentsline {subsection}{\numberline {2.2.9}7. Shared Data Pattern: Parallel-for-loop needs non-shared, private variables}{15}{subsection.2.2.9}
\contentsline {subsection}{\numberline {2.2.10}8. Race Condition: missing the mutual exclusion patterm}{16}{subsection.2.2.10}
\contentsline {subsection}{\numberline {2.2.11}9. Mutual Exclusion: two ways to ensure}{17}{subsection.2.2.11}
\contentsline {subsection}{\numberline {2.2.12}10. Mutual Exclusion Pattern: compare performance}{18}{subsection.2.2.12}
\contentsline {subsection}{\numberline {2.2.13}11. Task Decomposition Pattern using OpenMP section directive}{19}{subsection.2.2.13}
