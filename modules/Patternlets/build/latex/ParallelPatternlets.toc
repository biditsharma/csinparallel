\select@language {english}
\contentsline {chapter}{\numberline {1}Source Code}{2}{chapter.1}
\contentsline {chapter}{\numberline {2}Patternlet Examples}{3}{chapter.2}
\contentsline {section}{\numberline {2.1}Message Passing Parallel Patternlets}{3}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Source Code}{3}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}0. Single Program, Multiple Data}{3}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}1. The Master-Worker Implementation Strategy Pattern}{4}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}2. Message passing 1, using Send-Receive of a single value}{4}{subsection.2.1.4}
\contentsline {subsection}{\numberline {2.1.5}3. Message passing 2, using Send-Receive of an array of values}{5}{subsection.2.1.5}
\contentsline {subsection}{\numberline {2.1.6}4. A. Data Decomposition: on \emph {slices} using parallel-for (textual version)}{7}{subsection.2.1.6}
\contentsline {subsection}{\numberline {2.1.7}4. B. Data Decomposition: on \emph {slices} using parallel-for (visual version)}{7}{subsection.2.1.7}
\contentsline {subsection}{\numberline {2.1.8}5. A. Data Decomposition: on \emph {blocks} using parallel-for (textual version)}{9}{subsection.2.1.8}
\contentsline {subsection}{\numberline {2.1.9}5. B. Data Decomposition: on \emph {blocks} using parallel-for (visual version)}{10}{subsection.2.1.9}
\contentsline {subsection}{\numberline {2.1.10}6. Broadcast: a special form of message passing}{11}{subsection.2.1.10}
\contentsline {subsection}{\numberline {2.1.11}7. Collective Communication: Reduction}{12}{subsection.2.1.11}
\contentsline {subsection}{\numberline {2.1.12}8. Collective communication: Scatter for message-passing data decomposition}{13}{subsection.2.1.12}
\contentsline {subsection}{\numberline {2.1.13}9. Collective communication: Gather for message-passing data decomposition}{14}{subsection.2.1.13}
\contentsline {subsection}{\numberline {2.1.14}10. Collective Communication: Barrier}{15}{subsection.2.1.14}
\contentsline {section}{\numberline {2.2}Shared Memory Parallel Patternlets in OpenMP}{16}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Source Code}{16}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}0. The basic fork-join pattern}{16}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}1. Fork-join: setting the number of threads}{17}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}2. Single Program, multiple data}{18}{subsection.2.2.4}
\contentsline {subsection}{\numberline {2.2.5}3. Single Program, multiple data}{18}{subsection.2.2.5}
\contentsline {subsection}{\numberline {2.2.6}4. Barrier}{19}{subsection.2.2.6}
\contentsline {subsection}{\numberline {2.2.7}5. Master-Worker Implementation Strategy}{20}{subsection.2.2.7}
\contentsline {subsection}{\numberline {2.2.8}6. Shared Data Decomposition Pattern: blocking of threads in a parallel for loop}{21}{subsection.2.2.8}
\contentsline {subsection}{\numberline {2.2.9}7. Shared Data Decomposition Pattern: striping of threads in a parallel for loop}{21}{subsection.2.2.9}
\contentsline {subsection}{\numberline {2.2.10}8. Collective Communication: Reduction}{22}{subsection.2.2.10}
\contentsline {subsection}{\numberline {2.2.11}9. Shared Data Pattern: Parallel-for-loop needs non-shared, private variables}{23}{subsection.2.2.11}
\contentsline {subsection}{\numberline {2.2.12}10. Race Condition: missing the mutual exclusion patterm}{24}{subsection.2.2.12}
\contentsline {subsection}{\numberline {2.2.13}11. Mutual Exclusion: two ways to ensure}{25}{subsection.2.2.13}
\contentsline {subsection}{\numberline {2.2.14}12. Mutual Exclusion Pattern: compare performance}{26}{subsection.2.2.14}
\contentsline {subsection}{\numberline {2.2.15}13. Task Decomposition Pattern using OpenMP section directive}{27}{subsection.2.2.15}
