\select@language {english}
\contentsline {chapter}{\numberline {1}Parallel Programming Patterns}{2}{chapter.1}
\contentsline {section}{\numberline {1.1}An organization of parallel patterns}{2}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Strategies}{2}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Concurrent Execution Mechanisms}{2}{subsection.1.1.2}
\contentsline {chapter}{\numberline {2}Message Passing Parallel Patternlets}{4}{chapter.2}
\contentsline {section}{\numberline {2.1}Source Code}{4}{section.2.1}
\contentsline {section}{\numberline {2.2}0. Single Program, Multiple Data}{4}{section.2.2}
\contentsline {section}{\numberline {2.3}1. The Master-Worker Implementation Strategy Pattern}{5}{section.2.3}
\contentsline {section}{\numberline {2.4}2. Message passing 1, using Send-Receive of a single value}{5}{section.2.4}
\contentsline {section}{\numberline {2.5}3. Message passing 2, using Send-Receive of an array of values}{6}{section.2.5}
\contentsline {section}{\numberline {2.6}4. A. Data Decomposition: on \emph {slices} using parallel-for (textual version)}{8}{section.2.6}
\contentsline {section}{\numberline {2.7}4. B. Data Decomposition: on \emph {slices} using parallel-for (visual version)}{8}{section.2.7}
\contentsline {section}{\numberline {2.8}5. A. Data Decomposition: on \emph {blocks} using parallel-for (textual version)}{10}{section.2.8}
\contentsline {section}{\numberline {2.9}5. B. Data Decomposition: on \emph {blocks} using parallel-for (visual version)}{11}{section.2.9}
\contentsline {section}{\numberline {2.10}6. Broadcast: a special form of message passing}{13}{section.2.10}
\contentsline {section}{\numberline {2.11}7. Collective Communication: Reduction}{14}{section.2.11}
\contentsline {section}{\numberline {2.12}8. Collective communication: Scatter for message-passing data decomposition}{14}{section.2.12}
\contentsline {section}{\numberline {2.13}9. Collective communication: Gather for message-passing data decomposition}{15}{section.2.13}
\contentsline {section}{\numberline {2.14}10. Collective Communication: Barrier}{16}{section.2.14}
\contentsline {chapter}{\numberline {3}Shared Memory Parallel Patternlets in OpenMP}{18}{chapter.3}
\contentsline {section}{\numberline {3.1}Source Code}{18}{section.3.1}
\contentsline {section}{\numberline {3.2}Patternlets Grouped By Type}{19}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Shared Memory Program Structure and Coordination Patterns}{19}{subsection.3.2.1}
\contentsline {subsubsection}{0. Program Structure Implementation Strategy: The basic fork-join pattern}{19}{subsubsection*.3}
\contentsline {subsubsection}{1. Program Structure Implementation Strategy: Fork-join with setting the number of threads}{20}{subsubsection*.4}
\contentsline {subsubsection}{2. Program Structure Implementation Strategy: Single Program, multiple data}{21}{subsubsection*.5}
\contentsline {subsubsection}{3. Program Structure Implementation Strategy: Single Program, multiple data with user-defined number of threads}{24}{subsubsection*.6}
\contentsline {subsubsection}{4. Coordination: Synchronization with a Barrier}{25}{subsubsection*.7}
\contentsline {subsubsection}{5. Program Structure: The Master-Worker Implementation Strategy}{27}{subsubsection*.8}
\contentsline {subsection}{\numberline {3.2.2}Data Decomposition Algorithm Strategies and Related Coordination Strategies}{28}{subsection.3.2.2}
\contentsline {subsubsection}{6. Shared Data Decomposition Algorithm Strategy: chunks of data per thread using a parallel for loop implementation strategy}{28}{subsubsection*.9}
\contentsline {subsubsection}{7. Shared Data Decomposition Algorithm Strategy: one iteration per thread in a parallel for loop implementation strategy}{31}{subsubsection*.10}
\contentsline {subsubsection}{8. Coordination Using Collective Communication: Reduction}{32}{subsubsection*.11}
\contentsline {paragraph}{Something to think about}{34}{paragraph*.12}
\contentsline {subsection}{\numberline {3.2.3}Patterns used when threads share data values}{34}{subsection.3.2.3}
\contentsline {subsubsection}{9. Shared Data Algorithm Strategy: Parallel-for-loop pattern needs non-shared, private variables}{34}{subsubsection*.13}
\contentsline {subsubsection}{10. Race Condition: missing the mutual exclusion coordination pattern}{35}{subsubsection*.14}
\contentsline {subsubsection}{11. The Mutual Exclusion Coordination Pattern: two ways to ensure}{36}{subsubsection*.15}
\contentsline {subsubsection}{12. Mutual Exclusion Coordination Pattern: compare performance}{37}{subsubsection*.16}
\contentsline {subsubsection}{13. Mutual Exclusion Coordination Pattern: language difference}{38}{subsubsection*.17}
\contentsline {paragraph}{Some Explanation}{39}{paragraph*.18}
\contentsline {subsection}{\numberline {3.2.4}Task Decomposition Algorithm Strategies}{40}{subsection.3.2.4}
\contentsline {subsubsection}{14. Task Decomposition Algorithm Strategy using OpenMP section directive}{40}{subsubsection*.19}
\contentsline {subsection}{\numberline {3.2.5}Categorizing Patterns}{41}{subsection.3.2.5}
