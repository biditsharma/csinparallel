<html><head><title>OpenMP Next steps: Fixing our OpenMP code</title><style type="text/css">ol{margin:0;padding:0}.c10{list-style-type:lower-latin;margin:0;padding:0}.c12{font-size:18pt;font-family:"Times New Roman";font-weight:bold}.c9{max-width:468pt;background-color:#ffffff;padding:72pt 72pt 72pt 72pt}.c11{list-style-type:disc;margin:0;padding:0}.c8{padding-left:0pt;margin-left:72pt}.c1{font-size:12pt;font-family:"Times New Roman"}.c13{font-size:9pt;font-family:"Times New Roman"}.c0{font-size:12pt;font-family:"Courier New"}.c5{font-size:9pt;font-family:"Courier New"}.c4{padding-left:0pt;margin-left:36pt}.c2{direction:ltr}.c3{font-style:italic}.c7{margin-left:35pt}.c6{height:11pt}.title{padding-top:24pt;line-height:1.15;text-align:left;color:#000000;font-size:36pt;font-family:"Arial";font-weight:bold;padding-bottom:6pt}.subtitle{padding-top:18pt;line-height:1.15;text-align:left;color:#666666;font-style:italic;font-size:24pt;font-family:"Georgia";padding-bottom:4pt}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{padding-top:24pt;line-height:1.15;text-align:left;color:#000000;font-size:24pt;font-family:"Arial";font-weight:bold;padding-bottom:6pt}h2{padding-top:18pt;line-height:1.15;text-align:left;color:#000000;font-size:18pt;font-family:"Arial";font-weight:bold;padding-bottom:4pt}h3{padding-top:14pt;line-height:1.15;text-align:left;color:#000000;font-size:14pt;font-family:"Arial";font-weight:bold;padding-bottom:4pt}h4{padding-top:12pt;line-height:1.15;text-align:left;color:#000000;font-size:12pt;font-family:"Arial";font-weight:bold;padding-bottom:2pt}h5{padding-top:11pt;line-height:1.15;text-align:left;color:#000000;font-size:11pt;font-family:"Arial";font-weight:bold;padding-bottom:2pt}h6{padding-top:10pt;line-height:1.15;text-align:left;color:#000000;font-size:10pt;font-family:"Arial";font-weight:bold;padding-bottom:2pt}</style></head><body class="c9"><p class="c2"><span class="c12">Creating a correct threaded version</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">A program has a </span><span class="c1 c3">race condition</span><span class="c1">&nbsp;if the correct behavior of that program depends on the timing of its execution. With 2 or more threads, the program </span><span class="c0">trap-omp.C</span><span class="c1">&nbsp;has a race condition concerning the shared variable </span><span class="c0">integral</span><span class="c1">, which is the accumulator for the summation performed by that program&#39;s </span><span class="c0">for</span><span class="c1">&nbsp;loop.</span></p><p class="c2 c6"><span class="c1"></span></p><ol class="c11" start="1"><li class="c4 c2"><span class="c1">When </span><span class="c0">threadct == 1</span><span class="c1">, the single thread of execution updates the shared variable </span><span class="c0">integral</span><span class="c1">&nbsp;on every iteration, by reading the prior value of the memory location </span><span class="c0">integral</span><span class="c1">, computing and adding the value </span><span class="c0">f(a+i*h)</span><span class="c1">, then storing the result into that memory location </span><span class="c0">integral</span><span class="c1">. (Recall that a </span><span class="c0">variable</span><span class="c1">&nbsp;is a named location in main memory.)</span></li><li class="c2 c4"><span class="c1">But when </span><span class="c0">threadct &gt; 1</span><span class="c1">, there are at least two independent threads, executed on separate physical cores, that are reading then writing the memory location </span><span class="c0">integral</span><span class="c1">. The incorrect answer results when the reads and writes of that memory location get out of order. Here is one example of how unfortunate ordering can happen with two threads:</span></li></ol><p class="c2 c6"><span class="c13"></span></p><p class="c2 c7"><span class="c5">Thread 1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp;Thread 2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c2 c7"><span class="c5">code: &nbsp; integral += f(a+i*h); &nbsp; &nbsp; &nbsp;| &nbsp;code: &nbsp; integral += f(a+i*h); &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c2 c7"><span class="c5">exec: &nbsp; 1. read value of &nbsp;integral | &nbsp;exec: &nbsp; </span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; 2. add &nbsp;f(a+i*h) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. read value of &nbsp;integral</span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. add &nbsp;f(a+i*h) &nbsp; &nbsp; &nbsp;</span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; 3. write sum to &nbsp;integral &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c2 c7"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. write sum to &nbsp;integral</span></p><p class="c2 c7 c6"><span class="c1"></span></p><p class="c2 c7"><span class="c1">In this example, during one poorly timed iteration for each thread, Thread 2 reads the value of the memory location </span><span class="c0">integral</span><span class="c1">&nbsp;before Thread 1 can write its sum back to </span><span class="c0">integral</span><span class="c1">. The consequence is that Thread 2 replaces (overwrites) Thread 1&#39;s value of </span><span class="c0">integral</span><span class="c1">, so the amount added by Thread 1 is omitted from the final value of the accumulator </span><span class="c0">integral</span><span class="c1">.</span></p><p class="c2 c6 c7"><span class="c1"></span></p><p class="c2 c7"><span class="c1">Can you think of other situations where unfortunate ordering of thread operations leads to an incorrect value of </span><span class="c0">integral</span><span class="c1">? Write down at least one other bad timing scenario.</span></p><p class="c2 c7"><span class="c1 c3">Note:</span><span class="c1">&nbsp;Thousands of occurrences of bad timing lead to the computed answer for </span><span class="c0">integral</span><span class="c1">&nbsp;being off by often 25% or more.</span></p><p class="c2 c7 c6"><span class="c1"></span></p><ol class="c11" start="1"><li class="c4 c2"><span class="c1">One approach to avoiding this program&#39;s race condition is to use a separate local variable </span><span class="c0">integral</span><span class="c1">&nbsp;for each thread instead of a global variable that is shared by all the threads. But declaring </span><span class="c0">integral</span><span class="c1">&nbsp;to be </span><span class="c0">private</span><span class="c1">&nbsp;instead of </span><span class="c0">shared</span><span class="c1">&nbsp;in the pragma will only generate </span><span class="c0">threadct</span><span class="c1">&nbsp;partial sums in those local variables named </span><span class="c0">integral</span><span class="c1">&nbsp;-- the partial sums in those temporary local variables will </span><span class="c1 c3">not</span><span class="c1">&nbsp;be added to the program&#39;s variable </span><span class="c0">integral</span><span class="c1">. In fact, the value in those temporary local variables will be discarded when each thread finishes its work for the </span><span class="c0">parallel for</span><span class="c1">&nbsp;if we simply make </span><span class="c0">integral</span><span class="c1">&nbsp;</span><span class="c0">private</span><span class="c1">&nbsp;instead of </span><span class="c0">shared</span><span class="c1">.</span></li><li class="c4 c2"><span class="c1">Can you re-explain this situation in your own words?</span></li></ol><ol class="c11" start="1"><li class="c4 c2"><span class="c1">Fortunately, OpenMP provides a convenient and effective solution to this problem.</span></li></ol><ol class="c11" start="1"><li class="c4 c2"><span class="c1">The OpenMP clause &nbsp; </span><span class="c0">reduction(+: integral)</span><span class="c1">&nbsp; &nbsp;will</span></li></ol><ol class="c10" start="1"><li class="c2 c8"><span class="c1">cause the variable </span><span class="c0">integral</span><span class="c1">&nbsp;to be </span><span class="c0">private</span><span class="c1">&nbsp;(local) during the execution of each thread, </span><span class="c1 c3">and</span></li><li class="c8 c2"><span class="c1">add the results of all those </span><span class="c0">private</span><span class="c1">&nbsp;variables, </span><span class="c1 c3">then finally</span></li><li class="c8 c2"><span class="c1">store that sum of </span><span class="c0">private</span><span class="c1">&nbsp;variables in the </span><span class="c1 c3">global</span><span class="c1">&nbsp;variable named </span><span class="c0">integral</span><span class="c1">.</span></li></ol><ol class="c11" start="2"><li class="c4 c2"><span class="c1">Add this clause to your OpenMP pragma, and remove the variable </span><span class="c0">integral</span><span class="c1">&nbsp;from the </span><span class="c0">shared</span><span class="c1">&nbsp;clause, then recompile and test your program. You should now see the correct answer 2.0 when computing with multiple threads -- a correct multi-core program!</span></li></ol><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">A code segment is said to be </span><span class="c1 c3">thread-safe</span><span class="c1">&nbsp;if it remains correct when executed by multiple independent threads. The body of this loop is </span><span class="c1 c3">not</span><span class="c1">&nbsp;thread-safe.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">Some libraries are identified as thread-safe, meaning that each function in that library is thread-safe. Of course, calling a thread-safe function doesn&#39;t insure that the code with that function call is thread-safe. For example, the function </span><span class="c0">f()</span><span class="c1">&nbsp;in our example, is thread-safe, but the body of that loop is </span><span class="c1 c3">not</span><span class="c1">&nbsp;thread-safe.</span></p><p class="c2 c6"><span></span></p></body></html>